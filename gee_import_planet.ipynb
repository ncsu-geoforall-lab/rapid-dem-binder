{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLlMRmNaykvI"
   },
   "source": [
    "# Rapid-DSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA0vAO6oye8m"
   },
   "source": [
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxQN9JsVYaeW",
    "outputId": "500ef209-5d2f-4a7c-8705-9967822e6454"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0oMk9FFycTk",
    "outputId": "cf99bd32-eaab-477a-9411-f38c21232a2f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import Image\n",
    "\n",
    "# This is where pip is installing modules so we need to add it to the system path.\n",
    "os.environ['PATH'] += \":/root/.local/bin\"\n",
    "\n",
    "!pip install geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "!pip install rasterio\n",
    "import rasterio\n",
    "\n",
    "!pip install planet --user #v1.4.6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4V7vIFRyzC5"
   },
   "source": [
    "# Authenticate Goolge Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejiLlZr024ip"
   },
   "source": [
    "#### Google CoLab Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evDvo6Bm2171"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMwLOrAV24Qp"
   },
   "source": [
    "#### Mount Google Drive\n",
    "\n",
    "We will store figures here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJ01-Qxay5Xp",
    "outputId": "2a359f85-2bf7-4a85-d7fc-0bf17da07136"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lz-gl1L2v8E"
   },
   "source": [
    "#### Google Earth Engine Cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYLhm2G7zD-f",
    "outputId": "987c9da3-11d3-4104-c314-d92fd96c4161"
   },
   "outputs": [],
   "source": [
    "!earthengine authenticate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Kwhib6U2ppr"
   },
   "source": [
    "#### Google Earth Engine for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEN64_5b0Guc",
    "outputId": "e94dd17d-408e-4bc3-e2c5-abea6c8a678d"
   },
   "outputs": [],
   "source": [
    "# Import the Earth Engine library.\n",
    "import ee\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayRq_I0nzig4"
   },
   "source": [
    "# Default Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMbizJDI2k-K"
   },
   "source": [
    "#### Goolge Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kh3P1NY2znGA"
   },
   "outputs": [],
   "source": [
    "os.environ['GCP_PROJECT_ID'] = project_id = 'rapid-dsm'\n",
    "planet_gcp_directory = 'planet_scope'\n",
    "os.environ['PL_GCP_SERVICE_ACCOUNT'] = planet_service_account = \"<Your Google Cloud Platform Serivce Account>\"\n",
    "os.environ['PL_GCP_CREDS_JSON'] = google_creds_json = \"creds.json\"\n",
    "\n",
    "## Google Drive Save Location\n",
    "figures_save_location = \"<Your Google Drive Save Location>\"\n",
    "\n",
    "## Google Earth Engien Data\n",
    "os.environ['GEE_PROJECT_FOLDER'] = gee_project_folder = \"<Your Google Earth Engine Project Folder>\"\n",
    "os.environ['GEE_IMAGECOLLECTION'] = imageCollection = os.path.join(gee_project_folder, \"planetscope\")\n",
    "os.environ['GEE_IMAGECOLLECTION_AOI'] = gee_imagecollection_aoi = os.path.join(gee_project_folder, \"aoi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ9IBofpzTXB"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "storage_client = storage.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz47fUhmMbOT"
   },
   "source": [
    "## AOI: Walnut Creek Subwatershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "xlNcG-TOMYp1",
    "outputId": "ca2e2209-49ea-4a2c-be10-3953e6cbaaaf"
   },
   "outputs": [],
   "source": [
    "# Data from Google Earth Engine \n",
    "# HUC12: USGS Watershed Boundary Dataset of Subwatersheds\n",
    "subwatershed = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\n",
    "aoi = (subwatershed.filter(\n",
    "  ee.Filter.And(\n",
    "    ee.Filter.eq(\"huc12\", \"030202011101\"),\n",
    "    ee.Filter.eq(\"states\", \"NC\"),\n",
    "    ee.Filter.eq(\"name\", \"Walnut Creek\")\n",
    "    )\n",
    "  ))\n",
    "\n",
    "url = aoi.getDownloadUrl(filetype=\"GEOJSON\")\n",
    "df_aoi = gpd.read_file(url)\n",
    "# df_aoi.plot()\n",
    "df_envelope = gpd.GeoDataFrame(geometry=gpd.GeoSeries(df_aoi['geometry'].envelope))\n",
    "df_envelope.plot()\n",
    "print(df_envelope.area)\n",
    "aoi = df_envelope.to_file(\"aoi.json\", driver='GeoJSON')\n",
    "#make shapefile for GEE later\n",
    "df_envelope.to_file(\"aoi\")\n",
    "with open(\"aoi.json\", \"r\") as f:\n",
    "  aoi_json = json.loads(f.read())\n",
    "  print(aoi_json['features'][0]['geometry'])\n",
    "  os.environ['AOI_STRING'] = AOI_STRING = str(aoi_json['features'][0]['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Se_7U_AyMVA0"
   },
   "source": [
    "## Random AOI that happens to capture the two AOIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2YBCEsUFma3"
   },
   "outputs": [],
   "source": [
    "# original \n",
    "os.environ['AOI_STRING'] = AOI_STRING = '{\"type\": \"Polygon\",\"coordinates\": [[[-78.79113513335422,35.73453757221374],\t[-78.654824101583,35.73453757221374],[-78.654824101583,35.78778630839446],[-78.79113513335422,35.78778630839446],[-78.79113513335422,35.73453757221374]]]}'\n",
    "!touch aoi.json\n",
    "!echo '{\"type\": \"Polygon\",\"coordinates\": [[[-78.79113513335422,35.73453757221374],\t[-78.654824101583,35.73453757221374],[-78.654824101583,35.78778630839446],[-78.79113513335422,35.78778630839446],[-78.79113513335422,35.73453757221374]]]}' > aoi.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNbzw8UGHTnj"
   },
   "outputs": [],
   "source": [
    "# Set from https://planetlabs.github.io/planet-client-python/cli/reference.html\n",
    "os.environ['PL_API_KEY'] = planet_api_key = \"<Your PLANET API KEY>\"\n",
    "# Max cloud cover set at %10\n",
    "os.environ['PL_MAX_CLOUD_COVER'] = \"0.05\"\n",
    "# Look angle setting the off-Nadir filer settings\n",
    "os.environ['PL_MIN_LOOK'] = \"-2\"\n",
    "os.environ['PL_MAX_LOOK'] = \"2\"\n",
    "# Note: Sun Elevation - set in future form the images found in the inital search\n",
    "os.environ['PL_BUCKET'] = planet_bucket = 'gs://%s' % planet_gcp_directory\n",
    "os.environ['PL_TEMP_DATA'] = planet_tmp_data = 'planet'\n",
    "os.environ['PL_ASSET_TYPE'] = planet_asset_type = 'analytic_sr'\n",
    "os.environ['PL_ITEM_TYPE'] = planet_item_type = 'PSScene4Band'\n",
    "os.environ['PL_ITEM_IDS'] = pl_item_ids = ''\n",
    "os.environ['PL_BUNDLE'] = 'analytic_sr'\n",
    "os.environ['PL_TOOLS_FILE'] = planet_order_tool_file = \"tools.json\"\n",
    "os.environ['PL_CLOUD_CONFIG'] = planet_cloudconfig = 'pl_cloudconfig.json'\n",
    "os.environ['AOI_JSON'] = aoi_json = 'aoi.json'\n",
    "os.environ['AOI_SHAPEFILE_DIR'] = aoi_shapefile_dir = 'aoi/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcP65hWYOtlA"
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory to store results from Planet request\n",
    "!mkdir $PL_TEMP_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4SDK2LQ0Wrw"
   },
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oasSNcTC0qXw"
   },
   "outputs": [],
   "source": [
    "#@title Select a date range for your study area\n",
    "#@markdown Forms support many types of fields.\n",
    "start_date = '2018-01-01'  #@param {type: \"date\"}\n",
    "end_date = '2020-09-01'  #@param {type: \"date\"}\n",
    "#@markdown ---\n",
    "\n",
    "os.environ['PL_DATE_START'] = start_date\n",
    "os.environ['PL_DATE_END'] = end_date\n",
    "os.environ['PL_ORDER_NAME'] = order_name = \"rapid-dsm_{}_{}\".format(start_date,end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwG7UzruaSQv"
   },
   "source": [
    "# Get Planet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szEbEZnS13er"
   },
   "source": [
    "### Generate Planet Delivery JSON\n",
    "\n",
    "Planet's Orders API allows for direct delivery to cloud storage options such as Google Could Platform. To enable this service a bucket with Read and Write permissions must be generated for a specified service account. A new access key must be created and the returned json encoded as base64 for use with Planet's api. The below code will generate your bucket and set acl parameters and generate and encode google credentials for use with Planet's API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuQdmUDzuH_I",
    "outputId": "7d503e92-71f8-4ccc-b375-0d8f43b27dfb"
   },
   "outputs": [],
   "source": [
    "!gsutil ls -p $GCP_PROJECT_ID | grep $PL_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "brZK1pncJpSL",
    "outputId": "8bc81acf-7b10-4e5e-8829-c479db3e1775"
   },
   "outputs": [],
   "source": [
    "# Create delivery file so we can send download directly to Google Storage\n",
    "# API DOCS: https://developers.planet.com/docs/orders/delivery/\n",
    "\n",
    "# Add permissions to for Planet to read and write data to google cloud storage bucket.\n",
    "!gsutil acl ch -u $PL_GCP_SERVICE_ACCOUNT:WR $PL_BUCKET\n",
    "\n",
    "# https://cloud.google.com/docs/authentication/getting-started#command-line\n",
    "# Download credential json file for your google service account\n",
    "!gcloud iam service-accounts keys create $PL_GCP_CREDS_JSON --iam-account $PL_GCP_SERVICE_ACCOUNT\n",
    "\n",
    "# Encode cred.json as base64 so you can pass it as a planet order argument\n",
    "planet_cloud_storage_creds = !cat $PL_GCP_CREDS_JSON | base64 | tr -d '\\n'\n",
    "\n",
    "delivery = {\n",
    "    \"google_cloud_storage\": {\n",
    "        \"bucket\": planet_gcp_directory,\n",
    "        \"credentials\": planet_cloud_storage_creds[0],\n",
    "        \"path_prefix\": planet_gcp_directory\n",
    "        }\n",
    "    }\n",
    "\n",
    "with open(planet_cloudconfig, \"w+\") as m:\n",
    "  m.write(json.dumps(delivery))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4xuxuQ1FkwS"
   },
   "source": [
    "### Search Planet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Q3Ww3YLMwTR"
   },
   "outputs": [],
   "source": [
    "# Use planet cli to search for data\n",
    "!planet -k $PL_API_KEY data search --limit 500 --item-type $PL_ITEM_TYPE --asset-type $PL_ASSET_TYPE --date acquired gt $PL_DATE_START --date acquired lt $PL_DATE_END --range cloud_cover lte $PL_MAX_CLOUD_COVER --string-in quality_category \"standard\" --range view_angle lt $PL_MAX_LOOK --range view_angle gt $PL_MIN_LOOK --geom aoi.json > ps_search.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiD8ZGRDYCcB"
   },
   "outputs": [],
   "source": [
    "aoi = gpd.read_file('aoi.json')\n",
    "search_results = gpd.read_file('ps_search.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Fk-F_TQibOhB",
    "outputId": "d3fb1859-06bf-4436-d417-17fbb1496214"
   },
   "outputs": [],
   "source": [
    "search_results.describe()[['cloud_cover','gsd', 'sun_azimuth', 'sun_elevation', 'view_angle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "UXCt73jrb_pF",
    "outputId": "b95dd542-d510-4157-cd91-08f83099b75b"
   },
   "outputs": [],
   "source": [
    "start_image = search_results['acquired'].min()\n",
    "end_image = search_results['acquired'].max()\n",
    "print(\"Images from %s to %s\" % (start_image, end_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "o0it7kJAEuZ2",
    "outputId": "a218e949-d568-41c4-e855-a2c882e6d1be"
   },
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "w_test = search_results.sort_values(\"acquired\").set_index(pd.DatetimeIndex(search_results['acquired']))\n",
    "w_test_count = w_test.groupby(pd.Grouper(freq=\"M\")).count()\n",
    "w_test_count['count'] = w_test_count['id']\n",
    "w_test_count.head()\n",
    "# fig, ax = plt.subplots(figsize=(9, 6))\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "# ax.xaxis_date()\n",
    "g = w_test_count.plot(y='count', kind=\"bar\", ax=ax)\n",
    "g.axvline(x=12, linewidth=2, color='r',linestyle=\"--\", label=\"2019-01-22\")\n",
    "# date_form = DateFormatter(\"%m-%d-%Y\")\n",
    "# g.xaxis.set_major_formatter(date_form)\n",
    "plt.xticks(rotation=45)\n",
    "plt.suptitle('PlanetScope Image Date Range', y=1.01, fontsize=16)\n",
    "plt.title(\"Midpoint date 2019-01-22\", fontsize=14) \n",
    "plt.savefig(os.path.join(figures_save_location,\"PlanetScope Image Date Range\"),bbox_inches='tight')\n",
    "\n",
    "# 2019-01-22T14:59:44.500000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "mQGgYd8XZUvJ",
    "outputId": "f21e991e-b1cc-403f-fca2-6a29d0859710"
   },
   "outputs": [],
   "source": [
    "coverage = search_results.plot(column='acquired', alpha=0.5, cmap=\"tab10\")\n",
    "aoi.plot(color='white', edgecolor='black', ax=coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYh6mw-MFofn"
   },
   "source": [
    "### Create Planet Data Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzqtP1CDYefX"
   },
   "source": [
    "Get a list of Planet item ids to order for delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rZqy19QACZv"
   },
   "outputs": [],
   "source": [
    "item_ids = search_results[\"id\"].tolist()\n",
    "\n",
    "# pl_order['products'][0]['item_ids'] = item_ids\n",
    "\n",
    "# Set this environmental variable to be used in Planet API order request.\n",
    "os.environ['PL_ITEM_IDS'] = pl_item_ids = ','.join(map(str, item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7q43MJg6F5rE",
    "outputId": "2308a3b9-69f5-4fd2-99cf-dabd4af596b0"
   },
   "outputs": [],
   "source": [
    "#https://developers.planet.com/docs/orders/ordering/\n",
    "# !planet -k $PL_API_KEY orders create --name $PL_ORDER_NAME  --bundle $PL_BUNDLE  --clip $AOI_JSON --item-type $PL_ITEM_TYPE --id $PL_ITEM_IDS --cloudconfig $PL_CLOUD_CONFIG\n",
    "#Removed Clip tool for CGA account\n",
    "!planet -k $PL_API_KEY orders create --name $PL_ORDER_NAME  --bundle $PL_BUNDLE --item-type $PL_ITEM_TYPE --id $PL_ITEM_IDS --cloudconfig $PL_CLOUD_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agDWIQn2N4Oq"
   },
   "outputs": [],
   "source": [
    "pl_orders = !planet -k $PL_API_KEY orders list | jq -r \".orders[0].id\" \n",
    "# Get last Planet order ID to search for downloaded data\n",
    "os.environ['PL_ORDER_ID'] =order_id = pl_orders.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtmLajkcD1KH"
   },
   "source": [
    "### Wait for Planet Order to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "evno_EjHCEL6",
    "outputId": "63a004b0-6c2c-4137-b005-faf89d384078"
   },
   "outputs": [],
   "source": [
    "!planet -k $PL_API_KEY orders get $PL_ORDER_ID | jq -r \".last_message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwzjvdCPEA3d"
   },
   "source": [
    "# Upload Planet Data to Google Earth Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w8wbLxE2SLL"
   },
   "source": [
    "Before you can upload data to planet **you first need to create an ImageCollection in Google Earth Engine** to store the Images. The following script will load the data into the ImageCollection.\n",
    "\n",
    "> Google Earth Engine (GEE) doesn't provide a great API for this functionality yet. Ideally, you could just have GEE digest data directly from a Google Cloud Storage Bucket.\n",
    "\n",
    "https://github.com/samapriya/geeup provides another option for doing this, but I found it buggy and prone to breakages becasue of how it's implenented using a shadow browser to script through GEE UI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Bc_rrjBUZ5Q"
   },
   "source": [
    "## Create GEE ImageCollection if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49ziN2ckXTVF",
    "outputId": "364e4bc5-3062-42d5-fee9-b5155c6e49bd"
   },
   "outputs": [],
   "source": [
    "!earthengine --no-use_cloud_api create folder $GEE_PROJECT_FOLDER\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "hRV2_jfYUZjT",
    "outputId": "12599751-d2fa-4d6e-df35-535d55f3675c"
   },
   "outputs": [],
   "source": [
    "!earthengine --no-use_cloud_api create collection $GEE_IMAGECOLLECTION\n",
    "!earthengine --no-use_cloud_api asset set --time_start $PL_DATE_START --time_end $PL_DATE_END $GEE_IMAGECOLLECTION\n",
    "\n",
    "#Add search parameters to imagecollection metadata\n",
    "# !earthengine --no-use_cloud_api asset set -p '(string)name=42' users/username/asset_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beA6qecoWcJr"
   },
   "source": [
    "## Upload Area of interest to GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "vVjXXymvWaKU",
    "outputId": "9058b3b5-305c-45fb-a935-b2c258252e8b"
   },
   "outputs": [],
   "source": [
    "# It wants to read the file form cloud storage, so copy it to the project folder\n",
    "!gsutil -m cp -r $AOI_SHAPEFILE_DIR $PL_BUCKET/\"planet_scope\"/$PL_ORDER_ID/\n",
    "!earthengine --no-use_cloud_api upload table --asset_id=$GEE_PROJECT_FOLDER/aoi $PL_BUCKET/\"planet_scope\"/$PL_ORDER_ID/aoi/aoi.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLrC3n6sEBAr"
   },
   "source": [
    "### Copy manifest files from Planet Scope Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ns_SYld-w6Qo",
    "outputId": "4fbbac08-9672-47f8-cf8b-7f389c865758"
   },
   "outputs": [],
   "source": [
    "#copy planet image metadata to local directory to use during Google Earth Engine upload.\n",
    "!gsutil -m cp $PL_BUCKET/\"planet_scope\"/$PL_ORDER_ID/$PL_ITEM_TYPE/*.json $PL_TEMP_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RUXr7gOcXyl"
   },
   "source": [
    "Create Manifest file to send to to Google Earth Engine for data Ingest form Google Cloud Storage Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HyX_66HZyNRb",
    "outputId": "2735e8f8-2f23-42bb-e641-772304112267"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dt_format = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "# Get the start and end date of the image range to set manually on the ImageCollection\n",
    "# start_dt = datetime.strptime(start_image, dt_format)\n",
    "# end_dt = datetime.strptime(end_image, dt_format)\n",
    "# print(start_dt, end_dt)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Builds a manifest.json file for each image getting sent to GEE. The manifest file includes all metadata \n",
    "provided by PlanetScope allowing it to be accessable via GEE.\n",
    "\"\"\"\n",
    "for dirpath, dirnames, filenames in os.walk(planet_tmp_data):\n",
    "  for filename in filenames:\n",
    "    if filename.endswith(\".json\"):\n",
    "      with open(os.path.join(dirpath, filename)) as json_file:\n",
    "        \n",
    "        manifest = {\n",
    "          \"name\": imageCollection,\n",
    "          \"tilesets\": [\n",
    "            {\n",
    "              \"sources\": [\n",
    "                {\n",
    "                  \"uris\": []\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ],\n",
    "          \"start_time\": {\n",
    "            \"seconds\": None \n",
    "          }\n",
    "        }\n",
    "        data = json.load(json_file)\n",
    "        image_name = filename.split(\"_metadata.json\")[0] + \"_3B_AnalyticMS_SR.tif\"\n",
    "        manifest[\"name\"] = os.path.join(imageCollection, data['id'])\n",
    "        \n",
    "        url = os.path.join(planet_bucket, planet_gcp_directory, order_id,planet_item_type, image_name)\n",
    "        row = data[\"properties\"]\n",
    "        # row[\"system:time_start\"] = datetime.strptime(row[\"acquired\"],\"%Y-%m-%dT%H:%M:%S.%fz\").timestamp()\n",
    "        row[\"number_of_bands\"] = 4\n",
    "        manifest['start_time']['seconds'] = int(datetime.strptime(row['acquired'],\"%Y-%m-%dT%H:%M:%S.%fz\").timestamp())\n",
    "        manifest[\"tilesets\"][0][\"id\"] = \"ps\"\n",
    "        del row[\"ground_control\"]\n",
    "        manifest[\"properties\"] = row\n",
    "        manifest[\"tilesets\"][0][\"sources\"][0]['uris'].append(url)\n",
    "        # manifest[\"tilesets\"][0][\"sources\"].append(data_ps4bsr)\n",
    "        manifest_file_name = \"manifest_\" + data[\"id\"] + '.json'\n",
    "        print(manifest_file_name)\n",
    "        with open(manifest_file_name, 'w+') as m:\n",
    "          m.write(json.dumps(manifest))\n",
    "        !earthengine upload image --manifest {manifest_file_name}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeCP-737wrag"
   },
   "source": [
    "# Change Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S21Kgc4Vz3De"
   },
   "source": [
    "## Land Cover Land Change Value Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoQ4TBxiyF26",
    "outputId": "907870fc-2c14-416f-f0dc-2ff8c1c10410"
   },
   "outputs": [],
   "source": [
    "# OSM key value pairs to incldue\n",
    "# white_list = [\n",
    "#       #  'highway_residential', 'highway_primary','highway_motorway', 'highway_trunk',\n",
    "#        'landuse_grass', 'landuse_meadow',\n",
    "#        'natural_water', 'natural_wood', \"natural_grassland\",\n",
    "#        'surface_sand', 'surface_grass','surface_dirt',\n",
    "#        'parking_surface',\n",
    "#        'building_residential', 'building_retail','building_public', 'building_house']\n",
    "\n",
    "# Maps OSM key values to localized schema\n",
    "land_covers = {\n",
    "    'highway_residential': \"road\",\n",
    "    'highway_motorway': \"road\",\n",
    "    'highway_trunk': \"road\",\n",
    "    'highway_primary': \"road\",\n",
    "\n",
    "    'highway_secondary': \"road\",\n",
    "    'highway_tertiary': \"road\",\n",
    "    'highway_unclassified': \"road\",\n",
    "    'highway_motorway_link': \"road\",\n",
    "    'highway_trunk_link': \"road\",\n",
    "    'highway_primary_link': \"road\",\n",
    "    'highway_secondary_link': \"road\",\n",
    "    'highway_tertiary_link': \"road\",\n",
    "    'parking_surface': \"developed\",\n",
    "    # 'landuse_residential': \"residential\",\n",
    "    # 'landuse_construction': \"barren\",\n",
    "    # 'landuse_retail': \"retail\",\n",
    "    # 'surface_sand': \"barren\",\n",
    "    # 'surface_ground': \"barren\",\n",
    "    # 'surface_dirt': \"barren\",\n",
    "    'surface_grass': \"grass\",\n",
    "    'landuse_grass': \"grass\", \n",
    "    'landuse_meadow': \"grass\",\n",
    "    \"natural_grassland\": \"grass\",\n",
    "    'natural_water': \"water\",\n",
    "    # 'natural_wetland': \"wetland\",\n",
    "    'natural_wood': \"forest\",\n",
    "    'building_house': \"building\",\n",
    "    'building_residential': \"building\",\n",
    "    'building_retail': \"building\",\n",
    "    'building_public': \"building\"\n",
    "    # 'highway_construction': \"highway_construction\"\n",
    "  }\n",
    "\n",
    "query_keys = tuple(set([k.split('_')[0] for k in land_covers.keys()]))\n",
    "query_values = tuple(set([k.split('_')[1] for k in land_covers.keys()]))\n",
    "print(query_keys)\n",
    "# Map of human readable landclasses to coded values\n",
    "land_classes = {\n",
    "    \"road\": 0, # Developed\n",
    "    \"building\": 1, #Developed\n",
    "    \"barren\": 2,\n",
    "    \"forest\": 3,\n",
    "    \"grass\": 4, #Herbaceous\n",
    "    \"water\": 5,\n",
    "    \"developed\": 6\n",
    "  }\n",
    "\n",
    "#colors from https://www.mrlc.gov/data/legends/national-land-cover-database-2011-nlcd2011-legend\n",
    "landcover_color_palette = [\n",
    "    'E29E8C', # Class 0 - road/highways         NLCD class color 22\n",
    "    'B50000', # Class 1 - Building dark red     NLCD class color 24\n",
    "    'D2CDC0', # Class 2 - barren                NLCD class color 31\n",
    "    '38814E', # Class 3 - Forest                NLCD class color 42\n",
    "    '85C77E', # Class 4 - Grass                 NLCD class color 41\n",
    "    '5475A8', # Class 5 -  water                 NLCD class color 11\n",
    "    'E8D1D1' # Class 5 -  developed             NLCD class color 21\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6Gfnt2pYReN"
   },
   "source": [
    "#### Priority Change Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLCeH9RayEsA"
   },
   "outputs": [],
   "source": [
    "# Scale the change importance \n",
    "\n",
    "# 0 = No Change\n",
    "# 1 = Probable Noise\n",
    "# 2 = Low \n",
    "# 3 = Medium\n",
    "# 4 = High\n",
    "\n",
    "change_priority = {\n",
    "    \"No Change\": 0,\n",
    "    \"road to building\": 7,\n",
    "    \"road to barren\": 4,\n",
    "    \"road to water\": 0,\n",
    "    \"road to grass\": 1,\n",
    "    \"road to forest\": 1,\n",
    "    \"road to developed\": 4,\n",
    "    \"building to road\": 1,\n",
    "    \"building to barren\": 7,\n",
    "    \"building to water\": 0,\n",
    "    \"building to grass\": 3,\n",
    "    \"building to forest\": 3,\n",
    "    \"building to developed\": 5,\n",
    "    \"barren to road\": 3,\n",
    "    \"barren to building\": 7,\n",
    "    \"barren to water\": 0,\n",
    "    \"barren to grass\": 2,\n",
    "    \"barren to forest\": 2,\n",
    "    \"barren to developed\": 5,\n",
    "    \"water to road\": 0,\n",
    "    \"water to building\": 0,\n",
    "    \"water to barren\": 0,\n",
    "    \"water to grass\": 0,\n",
    "    \"water to forest\": 0,\n",
    "    \"water to developed\": 0,\n",
    "    \"grass to road\": 3,\n",
    "    \"grass to building\": 7,\n",
    "    \"grass to barren\": 3,\n",
    "    \"grass to water\":0,\n",
    "    \"grass to forest\": 3,\n",
    "    \"grass to developed\": 5,\n",
    "    \"forest to road\":\t3,\n",
    "    \"forest to building\": 7,\n",
    "    \"forest to barren\": 7,\n",
    "    \"forest to water\":\t0,\n",
    "    \"forest to grass\":\t3,\n",
    "    \"forest to developed\":\t7,\n",
    "    \"developed to road\":\t3,\n",
    "    \"developed to building\": 7,\n",
    "    \"developed to barren\": 7,\n",
    "    \"developed to water\":\t0,\n",
    "    \"developed to grass\":\t3,\n",
    "    \"developed to forest\":\t3\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rSz-z2y0s0-"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8Dprqt3wuVu",
    "outputId": "5303286e-b4c0-4bab-dbc0-25dcfe797dce"
   },
   "outputs": [],
   "source": [
    "# Define a method for displaying Earth Engine image tiles to folium map.\n",
    "def add_ee_layer(self, eeImageObject, visParams, name):\n",
    "  mapID = ee.Image(eeImageObject).getMapId(visParams)\n",
    "  folium.raster_layers.TileLayer(\n",
    "    tiles = mapID['tile_fetcher'].url_format,\n",
    "    attr = \"Map Data Â© Google Earth Engine\",\n",
    "    name = name,\n",
    "    overlay = True,\n",
    "    control = True\n",
    "  ).add_to(self)\n",
    "\n",
    "# Add EE drawing method to folium.\n",
    "folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "def createNDVI(image):\n",
    "  ndvi = image.normalizedDifference(['b4', 'b3']).select([\"nd\"],[\"ndvi\"])\n",
    "  return ndvi\n",
    "\n",
    "def createNDWI(image):\n",
    "  ndwi = image.normalizedDifference(['b1', 'b4']).select([\"nd\"], [\"ndwi\"])\n",
    "  return ndwi\n",
    "\n",
    "def createNDCI(image):\n",
    "  ndci = image.normalizedDifference(['b4', 'b2']).select([\"nd\"], [\"ndci\"])\n",
    "  return ndci\n",
    "\n",
    "def createBSI(image):\n",
    "  #https://openprairie.sdstate.edu/cgi/viewcontent.cgi?article=4165&context=etd\n",
    "  bsi = image.expression(\n",
    "    '((RED + GREEN) - (RED + BLUE))/ ((NIR + GREEN) + (RED + BLUE)) * 100 + 100' , {\n",
    "      'NIR': image.select('b4'),\n",
    "      'RED': image.select('b3'),\n",
    "      'BLUE': image.select('b1'),\n",
    "      'GREEN': image.select('b2')\n",
    "    }).select(['b3'],['bsi'])\n",
    "  return bsi\n",
    "\n",
    "def createDSBI(image):\n",
    "  #Lingjia GuLingjia 2018\n",
    "  dsbi = image.expression(\n",
    "    '0.5 * (BLUE - RED) +0.5*(BLUE - GREEN)' , {\n",
    "      'NIR': image.select('b4'),\n",
    "      'RED': image.select('b3'),\n",
    "      'BLUE': image.select('b1'),\n",
    "      'GREEN': image.select('b2')\n",
    "    }).select(['constant'],['dsbi'])\n",
    "  return dsbi\n",
    "\n",
    "def createBSI_NDVI_index(image_bsi, image_ndvi):\n",
    "  image = image_bsi.addBands(image_ndvi)\n",
    "  ndbsvi = image.normalizedDifference(['bsi', 'ndvi']).select([\"nd\"], [\"ndbsiv\"])\n",
    "  return ndbsvi\n",
    "\n",
    "def createFeatureImportanceBarChart(classifier, label=\"\"):\n",
    "  fig, ax = plt.subplots(figsize=(9, 6))\n",
    "  classifier_dict = classifier.explain()\n",
    "  variable_importance = ee.Feature(None, ee.Dictionary(classifier_dict).get('importance'))\n",
    "  \n",
    "  print(\"Variable Importance\")\n",
    "  props = variable_importance.getInfo()[\"properties\"]\n",
    "  data = [{\"feature\":v, \"value\":props[v]} for v in props]\n",
    "  df_variable_importance = pd.DataFrame(data)\n",
    "  plt.title('%s Feature Importance' % label.capitalize(), fontsize=14) \n",
    "  sns.barplot(x=\"value\", y=\"feature\", data=df_variable_importance.sort_values(\"value\", ascending=False),\n",
    "            label=\"Feature Importance\", color=\"b\")\n",
    "  plt.savefig(os.path.join(figures_save_location,label + \"_FeatImportance\"))\n",
    "  return df_variable_importance.sort_values(\"value\", ascending=False)['feature']\n",
    "\n",
    "\n",
    "def generateFromToExpression(landclasses):\n",
    "  \"\"\"\n",
    "  Generates thematic change expression and labeling dictionary\n",
    "  @param landclasses land_class dictionary \n",
    "  \"\"\"\n",
    "  output = \"\"\n",
    "  from_to_labels = {\n",
    "      \"No Change\": 0\n",
    "  }\n",
    "  for form_value_key in land_classes:\n",
    "    from_value = land_classes[form_value_key]\n",
    "    for to_value_key in land_classes:\n",
    "      to_value = land_classes[to_value_key]\n",
    "      if from_value != to_value:\n",
    "        change_class_value = str(from_value) + str(to_value)\n",
    "        change_class_key = \"%s to %s\" % (form_value_key, to_value_key)\n",
    "        from_to_labels[change_class_key] = change_class_value\n",
    "        base_text = \"(b('classification') == {0} && b('classification_1') == {1}) ? {2} :\".format(from_value, to_value, change_class_value)\n",
    "        output = output + base_text\n",
    "  output = output + \" 0\"\n",
    "  return({\"labels\": from_to_labels, \"expression\": output})\n",
    "\n",
    "result = generateFromToExpression(land_classes)\n",
    "thematic_change_expression = result['expression']\n",
    "print(result['labels'])\n",
    "print(thematic_change_expression)\n",
    "tmp_change_class_data = [{\"FromTo\":v, \"ClassID\":result[\"labels\"][v]} for v in result[\"labels\"]]\n",
    "df_change_classes = pd.DataFrame(tmp_change_class_data)\n",
    "df_change_classes[\"priority\"] = df_change_classes[\"FromTo\"].map(change_priority)\n",
    "\n",
    "def generateThematicChangeImage(from_image, to_image, expression):\n",
    "  # Add classified bands to same image\n",
    "  temp = from_image.addBands(to_image)\n",
    "  change_image = temp.expression(expression)\n",
    "  return change_image\n",
    "\n",
    "#This helper function returns a list of new band names.\n",
    "def getNewBandNames(prefix, bandNames):\n",
    "  seq = ee.List.sequence(1, len(bandNames))\n",
    "  z = [prefix + str(ee.Number(b).int().getInfo()) for b in seq.getInfo()]\n",
    "  return z\n",
    "  # return seq.map(lambda b: ee.String(\"%s%d\") % (prefix, ee.Number(b).int()))\n",
    "  # return seq.map(lambda b: ee.String(prefix).cat(str(ee.Number(b).int())))\n",
    "\n",
    "#This function accepts mean centered imagery, a scale and\n",
    "#a region in which to perform the analysis.  It returns the\n",
    "#Principal Components (PC) in the region as a new image.\n",
    "def getPrincipalComponents(centered, scale, region):\n",
    "  #Collapse the bands of the image into a 1D array per pixel.\n",
    "  arrays = centered.toArray();\n",
    "    \n",
    "  #Compute the covariance of the bands within the region.\n",
    "  covar = arrays.reduceRegion(\n",
    "      reducer = ee.Reducer.centeredCovariance(), \n",
    "      geometry= region,\n",
    "      scale= scale, \n",
    "      maxPixels=1e9, \n",
    "      bestEffort=True, \n",
    "      tileScale=16)\n",
    "   \n",
    "  #Get the 'array' covariance result and cast to an array.\n",
    "  #This represents the band-to-band covariance within the region.\n",
    "  covarArray = ee.Array(covar.get('array'))\n",
    "    \n",
    "  #Perform an eigen analysis and slice apart the values and vectors.\n",
    "  eigens = covarArray.eigen().getInfo()\n",
    "  # print(\"eigens\", eigens)\n",
    "  #This is a P-length vector of Eigenvalues.\n",
    "  eigenValues = ee.Array(eigens).slice(1, 0, 1);\n",
    "  # print(\"eigenValues\", eigenValues)\n",
    "  #This is a PxP matrix with eigenvectors in rows.\n",
    "  eigenVectors = ee.Array(eigens).slice(1, 1);\n",
    "  # print(\"eigenVectors\", eigenVectors)\n",
    "  #Convert the array image to 2D arrays for matrix computations.\n",
    "  arrayImage = arrays.toArray(1)\n",
    "  # print(\"arrayImage\", arrayImage)\n",
    "\n",
    "\n",
    "  #Left multiply the image array by the matrix of eigenvectors.\n",
    "  principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage)\n",
    "\n",
    "  #Turn the square roots of the Eigenvalues into a P-band image.\n",
    "  sdImage = ee.Image(eigenValues.sqrt())\n",
    "  sdImage = sdImage.arrayProject([0])\n",
    "  bandNames = centered.bandNames().getInfo()\n",
    "  sdImage = sdImage.arrayFlatten([getNewBandNames('sd', bandNames)])\n",
    "\n",
    "  #Turn the PCs into a P-band image, normalized by SD.\n",
    "  pc = principalComponents.arrayProject([0])#Throw out an an unneeded dimension, [[]] -> [].\n",
    "  pc = pc.arrayFlatten([getNewBandNames('pc',bandNames)])#Make the one band array image a multi-band image, [] -> image\n",
    "  pc = pc.divide(sdImage)#Normalize the PCs by their SDs.\n",
    "  return pc\n",
    "\n",
    "def createConfusionMatixFigure(testAccuracy, label=\"\"):\n",
    "  fig, ax = plt.subplots(figsize=(9, 6))\n",
    "  df_confusion_test = pd.DataFrame(testAccuracy.getInfo(), index=list(land_classes.keys()), columns=list(land_classes.keys()))\n",
    "  plt.title('%s Confusion Matrix' % label.capitalize(), fontsize=14) \n",
    "  sns.heatmap(df_confusion_test, annot=True, fmt=\"d\", linewidths=.5, ax=ax, cmap=\"Blues\")\n",
    "  plt.savefig(os.path.join(figures_save_location,label + \"_ConfMatrix\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMOuVXbkwXx5"
   },
   "source": [
    "### Function: Export exportEarthEngineImage(image, desc, imageName, region, saveLocation=\"GoogleDrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vT7nOlx_OZ2A"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def exportEarthEngineImage(image, desc, imageName, region,scale=3, saveLocation=\"GoogleDrive\"):\n",
    "  if (saveLocation == \"CloudStorage\"):\n",
    "    imageTask = ee.batch.Export.image.toCloudStorage(\n",
    "      image=image,\n",
    "      description=desc,\n",
    "      fileNamePrefix=imageName,\n",
    "      bucket=\"classification-results\",\n",
    "      scale=scale,\n",
    "      fileFormat='GeoTIFF',\n",
    "      skipEmptyTiles=True,\n",
    "      maxPixels=1e12,\n",
    "      # maxZoom=16,\n",
    "      crs='EPSG:3857',\n",
    "      formatOptions= {\n",
    "      \"cloudOptimized\": True\n",
    "      },\n",
    "      #dimensions=256,\n",
    "      # fileDimensions=256,\n",
    "      #shardSize=256\n",
    "      )\n",
    "  elif (saveLocation == \"GoogleDrive\"):\n",
    "    imageTask = ee.batch.Export.image.toDrive(\n",
    "    image=image,\n",
    "    folder=figures_save_location,\n",
    "    description='Image Export %s' % imageName,\n",
    "    fileNamePrefix=imageName,\n",
    "    scale=3,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    formatOptions= {\"cloudOptimized\": True},\n",
    "    region=region\n",
    "    )\n",
    "  elif (saveLocation == \"Asset\"):\n",
    "    imageTask = ee.batch.Export.image.toAsset(\n",
    "      assetId= imageName,\n",
    "      image=image,\n",
    "      description='Image Export',\n",
    "      fileNamePrefix=imageName,\n",
    "      scale=3,\n",
    "      fileFormat='GeoTIFF',\n",
    "      region=region.toGeoJSON()['coordinates']\n",
    "    )\n",
    "  else:\n",
    "    print(\"Unknown Save Location, must be either 'GoogleDrive','CloudStorage', or 'Asset\")\n",
    "    exit\n",
    "\n",
    "  imageTask.start()\n",
    "  while imageTask.active():\n",
    "    print('Polling for task (id: {}).'.format(imageTask.id))\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "def exportToDrive(image, imageLabel, resolution=30):\n",
    "  \"\"\"\n",
    "  param: image : ee.Image\n",
    "  param: imageLabel: string\n",
    "  param: resolution : export resolution (default = 30)\n",
    "  \"\"\"\n",
    "  ee.batch.Export.image.toDrive(\n",
    "    image=image,\n",
    "    folder=figures_save_location,\n",
    "    description=imageLabel,\n",
    "    fileNamePrefix=imageLabel,\n",
    "    scale=resolution,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    region=aoi.geometry(),\n",
    "    formatOptions= {\"cloudOptimized\": True}).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWRTkbUTmTys"
   },
   "outputs": [],
   "source": [
    "# aoi = ee.Geometry.Polygon([\n",
    "# \t\t\t\t\t\t\t[-78.79113513335422,35.73453757221374],\t\n",
    "# \t\t\t\t\t\t\t[-78.654824101583,35.73453757221374],\n",
    "# \t\t\t\t\t\t\t[-78.654824101583,35.78778630839446],\n",
    "# \t\t\t\t\t\t\t[-78.79113513335422,35.78778630839446],\n",
    "# \t\t\t\t\t\t\t[-78.79113513335422,35.73453757221374]\n",
    "# \t\t\t\t\t\t])\n",
    "\n",
    "# aoi = ee.Feature(g)\n",
    "\n",
    "aoi_bbox = ee.FeatureCollection(gee_imagecollection_aoi)\n",
    "\n",
    "subwatershed = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\n",
    "aoi = (subwatershed.filter(\n",
    "  ee.Filter.And(\n",
    "    ee.Filter.eq(\"huc12\", \"030202011101\"),\n",
    "    ee.Filter.eq(\"states\", \"NC\"),\n",
    "    ee.Filter.eq(\"name\", \"Walnut Creek\")\n",
    "    )\n",
    "  ))\n",
    "# print(aoi.first())\n",
    "coords = aoi.geometry().centroid().getInfo()['coordinates']\n",
    "center_map = [coords[1], coords[0]]\n",
    "\n",
    "\n",
    "#For paper figures\n",
    "centenial = ee.Geometry.Polygon([\n",
    "\t        \t\t[-78.68571281433105, 35.76256750220092],\n",
    "          \t\t[-78.66464138031006, 35.76256750220092],\n",
    "            \t[-78.66464138031006, 35.778723954134776],\n",
    "            \t[-78.68571281433105, 35.778723954134776],\n",
    "            \t[-78.68571281433105, 35.76256750220092 ]                        \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "cary_park = ee.Geometry.Polygon([\n",
    "\t        \t\t[\n",
    "              -78.78489017486572,\n",
    "              35.77962917544667\n",
    "            ],\n",
    "            [\n",
    "              -78.77480506896973,\n",
    "              35.77962917544667\n",
    "            ],\n",
    "            [\n",
    "              -78.77480506896973,\n",
    "              35.78788014067825\n",
    "            ],\n",
    "            [\n",
    "              -78.78489017486572,\n",
    "              35.78788014067825\n",
    "            ],\n",
    "            [\n",
    "              -78.78489017486572,\n",
    "              35.77962917544667\n",
    "            ]                       \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QeNsbxNhAk_"
   },
   "source": [
    "## Download OpenStreetMap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TIEeJHahMrQ",
    "outputId": "a254bdba-15d4-4d40-c3a7-66838591e61e"
   },
   "outputs": [],
   "source": [
    "# Query Google Big Query to generate training data for image classification.\n",
    "\n",
    "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
    "#old tag values removing roads to see if I can fix the max \n",
    "#AND tags.value in (\"water\", \"grass\",\"meadow\",\"grassland\", \"forest\", \"residential\",\"secondary\",\"tertiary\",\"unclassified\", \"primary\", \"motorway\", \"trunk\",\"motorway_link\",\"trunk_link\",\"primary_link\",\"secondary_link\",\"tertiary_link\", \"quarry\", \"farmland\", \"sand\", \"ground\", \"dirt\", \"wood\", \"retail\",\"public\", \"construction\", \"surface\", \"house\") \n",
    "\n",
    "df_landcover_samples = pd.io.gbq.read_gbq('''\n",
    "  SELECT feature_type,osm_timestamp, tags.key, tags.value, ST_ASGEOJSON(geometry) as geom\n",
    "  FROM `bigquery-public-data.geo_openstreetmap.planet_features` AS feats,\n",
    "  UNNEST(feats.all_tags) AS tags\n",
    "  WHERE tags.key in (\"building\", \"landuse\", \"highway\", \"water\", \"natural\", \"surface\", \"parking\") \n",
    "      AND tags.value in (\"water\", \"grass\",\"meadow\",\"grassland\", \"forest\", \"residential\",\"secondary\", \"primary\", \"motorway\", \"trunk\",\"trunk_link\",\"primary_link\",\"secondary_link\",\"tertiary_link\", \"quarry\", \"farmland\", \"sand\", \"ground\", \"dirt\", \"wood\", \"retail\",\"public\", \"construction\", \"surface\", \"house\") \n",
    "      AND ST_INTERSECTS(feats.geometry, ST_GEOGFROMGEOJSON('{\"type\": \"Polygon\",\"coordinates\": [[[ -78.782195642777026, 35.692691564447983 ],[ -78.531885144268472, 35.692691564447983 ],[ -78.531885144268472, 35.800084957942794 ],[ -78.782195642777026, 35.800084957942794 ],[ -78.782195642777026, 35.692691564447983 ]] ]}'))\n",
    "  ''', project_id=project_id)\n",
    "\n",
    " #project_id is defined in config\n",
    "# Create dataframe column that represents the OSM key value pair\n",
    "df_landcover_samples[\"keyvalue\"] = df_landcover_samples[\"key\"] + \"_\" + df_landcover_samples[\"value\"]\n",
    "\n",
    "# Map land cover and land class values to matching OSM key value combinations and drop and rows that don't match.\n",
    "df_landcover_samples[\"landcover\"] = df_landcover_samples[\"keyvalue\"].map(land_covers)\n",
    "df_landcover_samples[\"landclass\"] = df_landcover_samples[\"landcover\"].map(land_classes)\n",
    "df_landcover_samples = df_landcover_samples.dropna()\n",
    "df_landcover_samples.isnull().sum()\n",
    "df_null = df_landcover_samples[df_landcover_samples.isna().any(axis=1)]\n",
    "df_landcover_samples.to_csv('gbq_landcover.csv')\n",
    "assert df_null.size == 0, \"DataFrame df_null should have a size of 0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "w_Ym8wPM7zzY",
    "outputId": "353e01e4-95ae-4602-c3ce-4bd550b8f1f2"
   },
   "outputs": [],
   "source": [
    "df_landcover_samples.head()\n",
    "df_landcover_samples.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778
    },
    "id": "xjHnbnUE53uP",
    "outputId": "093ef3a4-c1ef-4e6c-e84c-2fb97b1c6f29"
   },
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(9, 6))\n",
    "sns.factorplot(\"landcover\", data=df_landcover_samples, aspect=2, kind=\"count\", color='steelblue')\n",
    "plt.title('OpenStreetMap Feature Counts', fontsize=14) \n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figures_save_location,\"osm_count\" + \"_by_type\"),dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V42nZq4WaEHq"
   },
   "source": [
    "## Export Data to CSV for Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IO4obnDHaDgq"
   },
   "outputs": [],
   "source": [
    "df_landcover_samples.to_csv('gbq_landcover.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "TmIhandOas-r",
    "outputId": "abdeda70-47f1-4575-e323-8cf7b308f2a9"
   },
   "outputs": [],
   "source": [
    "df_landcover_samples.head()\n",
    "df_landcover_samples['date'] = pd.to_datetime(df_landcover_samples.osm_timestamp,format='%Y%m', errors='coerce')\n",
    "df_landcover_samples['month_year'] = pd.to_datetime(df_landcover_samples['date']).dt.to_period('M')\n",
    "df_landcover_samples['count'] = 1\n",
    "df_landcover_samples.head()\n",
    "\n",
    "df_osm_temporal = df_landcover_samples.groupby(by=[\"month_year\",'landcover'], as_index=False).count()\n",
    "df_osm_temporal = df_osm_temporal.pivot( \"month_year\",\"landcover\", \"count\")\n",
    "df_osm_temporal = df_osm_temporal.resample('1M').count().fillna(0)\n",
    "ax = df_osm_temporal.plot(kind='area')\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.savefig(os.path.join(figures_save_location,\"osm_year_count\" + \"_by_type\"),dpi=300)\n",
    "# sns.heatmap(df_osm_temporal)\n",
    "# sns.scatterplot(data=df_osm_temporal)\n",
    "\n",
    "# df_osm_temporal.index\n",
    "# sns.relplot(x=\"month_year\", y=\"count\", hue=\"keyvalue\", data=df_osm_temporal);\n",
    "# sns.heatmap(df_osm_temporal.pivot(\"keyvalue\", \"month_year\", \"count\"), annot=True, fmt=\"f\")\n",
    "# sns.kdeplot(data=df_osm_temporal, x=date, y=count, levels=5, color=keyvalue, linewidths=1)\n",
    "# df_osm_temporal = df_osm_temporal.set_index(\"month_year\")\n",
    "# sns.scatterplot(data=df_osm_temporal,  y=\"count\", hue=\"keyvalue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7lKEFumjXg8"
   },
   "source": [
    "\n",
    "#### Convert raw OSM data to geojson so that it can be transformed into a GEE FeatureCollection.\n",
    "\n",
    "Buffer road data to match road size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUOBIjrbjTmg",
    "outputId": "0da252bc-af72-470b-c858-a935694976fa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert raw OSM data to geojson so that it can be transformed into a GEE FeatureCollection.\n",
    "\"\"\"\n",
    "sample_features = []\n",
    "road_features = []\n",
    "water_features = []\n",
    "for index, row in df_landcover_samples.iterrows():\n",
    "  geojson = json.loads(row[\"geom\"])\n",
    "\n",
    "  # if row[\"key\"] != \"highway\" and geojson[\"type\"] != \"Point\" and len(geojson[\"coordinates\"]) > 2:\n",
    "  #   geojson[\"type\"] = \"Polygon\"\n",
    "  #   first_node = geojson[\"coordinates\"][0]\n",
    "  #   node_len = len(geojson[\"coordinates\"]) - 1\n",
    "   \n",
    "  #   coordinates =[geojson[\"coordinates\"]]\n",
    "   \n",
    "  #   geojson[\"coordinates\"] = coordinates\n",
    "\n",
    "  feature = ee.Feature(geojson,{\"landcover\": row[\"landcover\"], \"landclass\": row[\"landclass\"]})\n",
    "  \n",
    "  #Values deriverd from https://safety.fhwa.dot.gov/geometric/pubs/mitigationstrategies/chapter3/3_lanewidth.cfm and \n",
    "  # https://wiki.openstreetmap.org/wiki/Highway_classes\n",
    "  if row[\"key\"] == \"highway\" and geojson[\"type\"] == \"LineString\":\n",
    "  #   if row['value'] == 'residential':\n",
    "  #     feature = feature.buffer(2.7 * 1)\n",
    "  #   elif row['value'] == 'unclassifed':\n",
    "  #      feature = feature.buffer(2.7 * 1)\n",
    "  #   elif row['value'] == 'tertiary': #new\n",
    "  #     feature = feature.buffer(2.7 * 2)\n",
    "  #   elif row['value'] == 'secondary': #new\n",
    "  #      feature = feature.buffer(3.6 * 2)\n",
    "  #   elif row['value'] == 'primary':\n",
    "  #      feature = feature.buffer(3.6 * 2)\n",
    "  #   elif row['value'] == 'trunk':\n",
    "  #      feature = feature.buffer(3.6 * 4)\n",
    "  #   elif row['value'] == 'motorway':\n",
    "  #      feature = feature.buffer(3.6 * 4)\n",
    "  #   elif row['value'] == 'motorway_link':\n",
    "  #      feature = feature.buffer(3.6 * 1)\n",
    "  #   elif row['value'] == 'trunk_link':\n",
    "  #      feature = feature.buffer(3.6 * 1)\n",
    "  #   elif row['value'] == 'primary_link':\n",
    "  #      feature = feature.buffer(3.6 * 1)\n",
    "  #   elif row['value'] == 'secondary_link':\n",
    "  #      feature = feature.buffer(3.6 * 1)\n",
    "  #   elif row['value'] == 'tertiary_link':\n",
    "  #      feature = feature.buffer(3.6 * 1)\n",
    "\n",
    "    road_features.append(feature)\n",
    "  elif row[\"value\"] == \"water\":\n",
    "    water_features.append(feature)\n",
    "  else:\n",
    "    sample_features.append(feature)\n",
    " \n",
    "\n",
    "\n",
    "print(\"Sample Features {}\".format(len(sample_features)))\n",
    "print(\"Road Features {}\".format(len(road_features)))\n",
    "print(\"Water Features {}\".format(len(water_features)))\n",
    "sample_feature_collection = ee.FeatureCollection(sample_features[0:(int(len(sample_features)/4))])\n",
    "water_feature_collection = ee.FeatureCollection(water_features)\n",
    "# print(sample_feature_collection.size())\n",
    "road_feature_collection = ee.FeatureCollection(road_features)\n",
    "road_class = ee.Image().byte().paint(road_feature_collection, \"landclass\").rename(\"landclass\")\n",
    "# classes = sample_feature_collection.filter(ee.Filter.notNull(['landclass'])).reduceToImage(properties=[\"landclass\"], reducer=ee.Reducer.first())\n",
    "classes = ee.Image().byte().paint(sample_feature_collection, \"landclass\").rename(\"landclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3OvcrwjQhif"
   },
   "source": [
    "##Load Planet ImageColelction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWp03u_D49Ts",
    "outputId": "189c9484-87af-43a6-e532-f8a6975f2830"
   },
   "outputs": [],
   "source": [
    "# Fetch Planet Data.\n",
    "\n",
    "start_image = '2018-01-30T15:21:54'\n",
    "end_image = '2019-12-31T15:38:18'\n",
    "start_image = \"2018-06-01\" \n",
    "end_image = \"2020-08-26\" \n",
    "# planet_scope = ee.ImageCollection('users/ctwhite/planetdata/rapid_dsm_aoi').filterDate(start_image, end_image).filterBounds(aoi) #Auto generated\n",
    "print(\"ImageCollection: \", imageCollection) \n",
    "planet_scope_ic = ee.ImageCollection(imageCollection)\n",
    "print(\"ImageCollection Size: \", planet_scope_ic.size().getInfo())\n",
    "\n",
    "planet_scope = (planet_scope_ic\n",
    "  .filterBounds(aoi)\n",
    "  .filterDate(start_image, end_image)\n",
    "  .filter(ee.Filter.gt('heavy_haze_percent', 0).Not())\n",
    "  .filter(ee.Filter.gt('light_haze_percent', 0).Not())\n",
    "  .filter(ee.Filter.eq('cloud_percent', 0)))\n",
    "\n",
    "print(\"ImageCollection Filtered Size: \", planet_scope.size().getInfo())\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYaga_ye1f-l"
   },
   "source": [
    "## Export OSM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "cvuzejLK1fPj",
    "outputId": "4d722e61-8efb-43db-8e3b-b20d9f55fdb9"
   },
   "outputs": [],
   "source": [
    "myMap = folium.Map(location=center_map, zoom_start=12, height=500)\n",
    "planet_scope_mosaic_log = planet_scope.median().log()\n",
    "planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "myMap.add_ee_layer(planet_scope_mosaic_log, planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "classes = sample_feature_collection.filterBounds(aoi).filter(ee.Filter.notNull(['landclass'])).reduceToImage(properties=[\"landclass\"], reducer=ee.Reducer.first()).clipToCollection(aoi)\n",
    "road_rast = road_feature_collection.filterBounds(aoi).filter(ee.Filter.notNull(['landclass'])).reduceToImage(properties=[\"landclass\"], reducer=ee.Reducer.first()).clipToCollection(aoi)\n",
    "water_class = water_feature_collection.filterBounds(aoi).filter(ee.Filter.notNull(['landclass'])).reduceToImage(properties=[\"landclass\"], reducer=ee.Reducer.first()).clipToCollection(aoi)\n",
    "aoi_rast = ee.Image().byte().paint(aoi)\n",
    "\n",
    "aoi_mask_tmp = aoi_rast.eq(1)\n",
    "aoi_mask = aoi_mask_tmp.Not()\n",
    "aoi_mask = aoi_mask.mask(aoi_mask)\n",
    "myMap.add_ee_layer(classes, {\"min\": 0, \"max\": 6, \"palette\": landcover_color_palette}, 'Trainging Classes ')\n",
    "# myMap.add_ee_layer(road_feature_collection.draw(color= 'blue', strokeWidth= 2), {}, 'Roads')\n",
    "\n",
    "myMap.add_ee_layer(water_class.clipToCollection(aoi), {\"min\": 0, \"max\": 6, \"palette\": landcover_color_palette}, 'Water Classes ')\n",
    "\n",
    "myMap.add_ee_layer(aoi_mask, {\"palette\": [\"blue\"], \"opacity\": 0.25}, 'AOI Mask')\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PeVsf1x-tNd"
   },
   "outputs": [],
   "source": [
    "sns.set_palette(sns.color_palette([ \"#%s\" % c if c is not \"purple\" else c for c in landcover_color_palette]))\n",
    "# sns.barplot(x=\"landclass\", y=\"freq\",hue='landclass', data=df_stratified_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ULxBOzBr2HaQ",
    "outputId": "9ac8271f-f6d0-4e50-9990-23461ac10c5b"
   },
   "outputs": [],
   "source": [
    "myMap = folium.Map(location=center_map, zoom_start=12, height=500)\n",
    "planet_scope_mosaic_log = planet_scope.median().log()\n",
    "planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "myMap.add_ee_layer(planet_scope_mosaic_log, planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "classes_rast = sample_feature_collection.filter(ee.Filter.notNull(['landclass'])).reduceToImage(properties=[\"landclass\"], reducer=ee.Reducer.first())\n",
    "aoi_rast = ee.Image().byte().paint(aoi)\n",
    "\n",
    "# Removed water for sample data raster\n",
    "aoi_mask_tmp = aoi_rast.eq(1)\n",
    "aoi_mask = aoi_mask_tmp.Not()\n",
    "aoi_mask = aoi_mask.mask(aoi_mask)\n",
    "myMap.add_ee_layer(classes_rast.updateMask(aoi_mask), {\"min\": 0, \"max\": 6, \"palette\": landcover_color_palette}, 'Sample Features')\n",
    "myMap.add_ee_layer(aoi_mask, {\"palette\": [\"blue\"], \"opacity\": 0.25}, 'AOI Mask')\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "display(myMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtQa-WsFjKXT"
   },
   "outputs": [],
   "source": [
    "#https://www.mrlc.gov/data/legends/national-land-cover-database-2016-nlcd2016-legend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufrKb1CDcbQ5"
   },
   "source": [
    "## Add Bare Earth Samples \n",
    "Derived from NDVI and BSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "ErAh69D7cnB_",
    "outputId": "d4a8bf6a-69b6-498d-d4f7-1f55bbbd0fcc"
   },
   "outputs": [],
   "source": [
    "ps_median = planet_scope.median().clipToCollection(aoi_bbox)\n",
    "\n",
    "bsiVisParam = {\"bands\":[\"bsi\"],\"min\":99.543,\"max\":103.578,\"palette\":[\"ff3e04\",\"ffb308\",\"ffec08\",\"ffffff\"],'dimensions': 1000};\n",
    "# Image(url=bsi.clip(aoi).getThumbUrl(bsiVisParam))\n",
    "\n",
    "# bare_earth_bsi = bsi.gte(103).And(bsi.lte(105.5)).And(ndvi.gt(0.16)).And(ndvi.lt(0.22)).selfMask()\n",
    "classes_mask = ps_median.where(classes.gt(0), -9999).neq(-9999).selfMask()\n",
    "ndvi = createNDVI(ps_median) #.updateMask(classes_mask)\n",
    "bsi = createBSI(ps_median) #.updateMask(classes_mask)\n",
    "ndwi = createNDWI(ps_median) #.updateMask(classes_mask)\n",
    "dsbi = createDSBI(ps_median)\n",
    "\n",
    "\n",
    "#experimental index to seperate grass, forest, and impervious\n",
    "# ndbsvi = createBSI_NDVI_index(bsi, ndvi)\n",
    "\n",
    "\n",
    "bare_earth_bsi = (\n",
    "    bsi.gt(103.5)\n",
    "      .And(bsi.lte(107))\n",
    "      .And(ndvi.gt(0.15))\n",
    "      .And(ndvi.lt(0.2))\n",
    "      # .And(ndwi.lt(0)) #Filter out water features\n",
    "      .selfMask())\n",
    "\n",
    "objectId = bare_earth_bsi.connectedComponents(ee.Kernel.plus(1), 128)\n",
    "# Compute the number of pixels in each object defined by the \"labels\" band.\n",
    "objectSize = objectId.select('labels').connectedPixelCount(128,False)\n",
    "# Get a pixel area image.\n",
    "pixelArea = ee.Image.pixelArea()\n",
    "# Multiply pixel area by the number of pixels in an object to calculate\n",
    "# the object area. The result is an image where each pixel\n",
    "# of an object relates the area of the object in m^2.\n",
    "objectArea = objectSize.multiply(pixelArea)\n",
    "# Map.addLayer(objectArea, null, 'objectArea');\n",
    "\n",
    "## Threshold the `objectArea` image to define a mask that will mask out\n",
    "areaMask = objectArea #.gte(5);\n",
    "\n",
    "# Update the mask of the `objectId` layer defined previously using the\n",
    "# minimum area mask just defined.\n",
    "bare_earth_samples = objectId.updateMask(classes_mask.select('b1')) #.updateMask(areaMask)\n",
    "bare_earth_vector = bare_earth_samples.select('labels').reduceToVectors(geometry=aoi,labelProperty='labels',scale=30 )\n",
    "\n",
    "\n",
    "# center_map = [35.752265080410844,-78.63944155399622]\n",
    "\n",
    "\n",
    "\n",
    "# Create a folium map object.\n",
    "print(center_map)\n",
    "myMap = folium.Map(location=center_map, zoom_start=14, height=500)\n",
    "planet_scope_mosaic_log = planet_scope.median().log().clipToCollection(aoi_bbox)\n",
    "planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "myMap.add_ee_layer(planet_scope_mosaic_log, planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "\n",
    "myMap.add_ee_layer(bsi.gt(104).And(bsi.lt(105)).selfMask(), {\"palette\": [\"yellow\"],\"bands\":[\"bsi\"],\"min\":102.7,\"max\":105,\"opacity\": 0.9}, 'BSI')\n",
    "myMap.add_ee_layer(ndvi.gt(0.25).And(ndvi.lt(0.27)).selfMask(), {\"palette\": [\"red\"], \"opacity\": 0.5}, 'NDVI')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(bare_earth_samples.bandNames().getInfo())\n",
    "myMap.add_ee_layer(bare_earth_samples.select(['labels']), {\"palette\": ['FF0000']}, 'Large hotspots')\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "display(myMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_tb_RKrcs31"
   },
   "outputs": [],
   "source": [
    "wake_building_permits_url = 'https://opendata.arcgis.com/datasets/5b8394817ec34097819534e67ccd4d8b_0.geojson'\n",
    "gdf_building_permits = gpd.read_file(wake_building_permits_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "3gFobci1ds0V",
    "outputId": "3fc2fbc4-66be-481f-f752-5d4c3e7f35c7"
   },
   "outputs": [],
   "source": [
    "# gdf_building_permits.plot()\n",
    "gdf_building_permits.describe()\n",
    "gdf_building_permits_filterd = gdf_building_permits[\n",
    "              (gdf_building_permits['PERMIT_STATUS'] == 'Complete') & \n",
    "              (gdf_building_permits['ISSUE_DATE']  >= \"2017-01-01\") & \n",
    "              (gdf_building_permits['FINALED_DATE']  <= end_image) & \n",
    "              # (gdf_building_permits['SQUARE_FEET']  >= 5000) &\n",
    "              (gdf_building_permits['WORK_CLASS']  == 'New Building or Addition') &\n",
    "              (gdf_building_permits['geometry'].isna() == False)\n",
    "              ]\n",
    "gdf_building_permits_filterd.describe()\n",
    "gdf_building_permits_filterd.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-gxqoIqvP_3",
    "outputId": "5fe6f4e9-69bb-46a8-b771-63619cde08d5"
   },
   "outputs": [],
   "source": [
    "gdf_building_permits_filterd.WORK_CLASS.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFr010BBhCoo",
    "outputId": "c0c7d1a8-91ff-4e68-d45e-0a5b4de299d1"
   },
   "outputs": [],
   "source": [
    "building_permit_features = []\n",
    "for i, r in gdf_building_permits_filterd.iterrows():\n",
    "  if r.empty is not True:\n",
    "    tmp_dict = r.to_dict()\n",
    "    del tmp_dict['geometry']\n",
    "    # print(tmp_dict)\n",
    "    # del tmp_dict['const']\n",
    "    # Square Feet field is not up to date so it does catch all constructions\n",
    "    # Set buffer value to 100m so it is more visible\n",
    "    buff_dist = (((r.SQUARE_FEET / 2.0) / 3.281) / 1000.0)\n",
    "    print(f\"SqFt: {r.SQUARE_FEET}, Buff Dist: {buff_dist}\")\n",
    "    feature = ee.Feature(ee.Geometry.Point(r.X, r.Y), {'sqft': r.SQUARE_FEET,'buf_dist':100,  'permit_type': r.PERMIT_TYPE, 'issue_data':r.ISSUE_DATE, 'work_class': r.WORK_CLASS})\n",
    "    building_permit_features.append(feature)\n",
    "    \n",
    "\n",
    "building_permits_feature_collection = ee.FeatureCollection(building_permit_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQyrJRtDttGg"
   },
   "source": [
    "## Export Before after Images to Google Cloud Storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUvW0gsTRIVW",
    "outputId": "5ffb144b-9c2c-46d0-9e9f-d6229fd24080"
   },
   "outputs": [],
   "source": [
    "\n",
    "# before_image = planet_scope.filterDate(\"2020-04-01\", \"2020-04-30\").median()\n",
    "# after_image = planet_scope.filterDate(\"2020-05-01\", \"2020-05-31\").median()\n",
    "\n",
    "# before_image = planet_scope.filterDate('2018-06-01', '2018-12-31').median().clip(aoi)\n",
    "# after_image = planet_scope.filterDate('2019-01-01', '2019-03-01').median().clip(aoi)\n",
    "# 2018-12-18T15:05:08 to 2019-02-26T14:54:21\n",
    "# Hardcoded for testing \n",
    "start_image = \"2018-06-01\" \n",
    "end_image = \"2020-08-26\"\n",
    "\n",
    "from datetime import datetime\n",
    "date_format = \"%Y-%m-%d\"\n",
    "# date_format = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "d1 = datetime.strptime(start_image,date_format)\n",
    "d2 = datetime.strptime(end_image,date_format)\n",
    "# date1 + (date2 - date1) / 2\n",
    "date_midpoint = d1 + (d2 - d1) / 2 # first dat\n",
    "print(date_midpoint.isoformat())\n",
    "print(date_midpoint)\n",
    "before_img_col = planet_scope.filterBounds(aoi).filterDate(start_image, date_midpoint)\n",
    "after_img_col = planet_scope.filterBounds(aoi).filterDate(date_midpoint, end_image)\n",
    "print(\"ImageCollection Before Size: \", before_img_col.size().getInfo())\n",
    "print(\"ImageCollection After Size: \", after_img_col.size().getInfo())\n",
    "\n",
    "before_image = before_img_col.median().toFloat().clipToCollection(aoi_bbox)\n",
    "after_image = after_img_col.median().toFloat().clipToCollection(aoi_bbox)\n",
    "\n",
    "# Try mosaic over median\n",
    "# before_image = before_img_col.mosaic().toFloat().clipToCollection(aoi_bbox)\n",
    "# after_image = after_img_col.mosaic().toFloat().clipToCollection(aoi_bbox)\n",
    "\n",
    "print(after_image.getInfo())\n",
    "\n",
    "# before_start_date = before_image.getInfo()\n",
    "# print(before_start_date)\n",
    "ps_collection_obcd = {\n",
    "    \"before\": before_image,\n",
    "    \"after\": after_image\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZmN9PrG98qd"
   },
   "outputs": [],
   "source": [
    "exportToDrive(before_image,\"ps_before_3m\", resolution=3)\n",
    "exportToDrive(after_image,\"ps_after_3m\", resolution=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "VtUn_HLPjLJE",
    "outputId": "9a76ca9a-0c43-401f-fe1b-f4e1a264cec6"
   },
   "outputs": [],
   "source": [
    "myMap = folium.Map(location=center_map, zoom_start=12, height=500)\n",
    "planet_scope_mosaic_log = planet_scope.median().log()\n",
    "planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "myMap.add_ee_layer(before_image.log(), planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "buffered_building_permits_feature_collection = building_permits_feature_collection.map(lambda f: f.buffer(f.get('buf_dist')))\n",
    "building_permits_rast = ee.Image().byte().paint(buffered_building_permits_feature_collection)\n",
    "\n",
    "myMap.add_ee_layer(building_permits_rast, {\"palette\": [\"yellow\"], \"opacity\": 0.60}, 'Building Permits')\n",
    "myMap.add_ee_layer(aoi_mask, {\"palette\": [\"blue\"], \"opacity\": 0.25}, 'AOI Mask')\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "display(myMap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtaSmEp3Ep8f"
   },
   "source": [
    "## Testing Statistical Threashold Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdo6IJ2PfNJE"
   },
   "outputs": [],
   "source": [
    "ndvi = createNDVI(ps_median)\n",
    "bsi = createBSI(ps_median)\n",
    "dsbi = createDSBI(ps_median)\n",
    "#experimental index to seperate grass, forest, and impervious\n",
    "ndbsvi = createBSI_NDVI_index(bsi, ndvi)\n",
    "count = 0\n",
    "\n",
    "def quantileIndexes(image, band, palette=[\"ff3e04\",\"ffb308\",\"ffec08\",\"ffffff\"]):\n",
    "  percentiles = image.reduceRegion(\n",
    "        reducer=ee.Reducer.percentile([10,25,50,75,90]),\n",
    "        geometry=aoi,\n",
    "        scale=30,\n",
    "        # tileScale=4,\n",
    "        maxPixels= 1e12)\n",
    "\n",
    "\n",
    "  percentile10th = ee.Number(percentiles.get(band+'_p10'))\n",
    "  lowerQuartile = ee.Number(percentiles.get(band+'_p25'))\n",
    "  median = ee.Number(percentiles.get(band+'_p50'))\n",
    "  upperQuartile = ee.Number(percentiles.get(band+'_p75'))\n",
    "  percentile90th = ee.Number(percentiles.get(band+'_p90'))\n",
    "  print(\"10th: {}\".format(percentile10th.getInfo()))\n",
    "  print(\"lower: {}\".format(lowerQuartile.getInfo()))\n",
    "  print(\"median: {}\".format(median.getInfo()))\n",
    "  print(\"upper: {}\".format(upperQuartile.getInfo()))\n",
    "  print(\"90th: {}\".format(percentile90th.getInfo()))\n",
    "\n",
    "  # Get AOI centroid\n",
    "  # center_map = aoi.geometry().centroid().getInfo()['coordinates'].reverse()\n",
    "  myMap = folium.Map(location=center_map, zoom_start=16, height=500)\n",
    "  planet_scope_mosaic_log = planet_scope.median().log().clip(aoi)\n",
    "  planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "  myMap.add_ee_layer(planet_scope_mosaic_log, planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "\n",
    "  \n",
    "  \n",
    "  #Low to High\n",
    "  myMap.add_ee_layer(image, {\"bands\":[band],\"min\":lowerQuartile.getInfo(),\"max\":upperQuartile,\"palette\":palette}, '%s low to High' %band)\n",
    "  #Low to Med\n",
    "  myMap.add_ee_layer(image, {\"bands\":[band],\"min\":lowerQuartile.getInfo(),\"max\":median.getInfo(),\"palette\":palette}, '%s low to Med' % band)\n",
    "  #Med to High\n",
    "  myMap.add_ee_layer(image, {\"bands\":[band],\"min\":median.getInfo(),\"max\":upperQuartile.getInfo(),\"palette\":palette}, '%s Med to High' % band)\n",
    "  #low\n",
    "  myMap.add_ee_layer(image, {\"bands\":[band],\"max\":lowerQuartile.getInfo(),\"palette\":palette}, '%s low' % band)\n",
    "  #high\n",
    "  myMap.add_ee_layer(image, {\"bands\":[band],\"min\":upperQuartile.getInfo(),\"palette\":palette}, '%s high' % band)\n",
    "\n",
    "  #masks\n",
    "  # myMap.add_ee_layer(water,{},\"Water Mask\")\n",
    "\n",
    "  \n",
    "  landcover_color_palette = [\n",
    "    'E29E8C', # Class 0 - road/highways         NLCD class color 22\n",
    "    'B50000', # Class 1 - Building dark red     NLCD class color 24\n",
    "    'D2CDC0', # Class 2 - barren                NLCD class color 31\n",
    "    '38814E', # Class 3 - Forest                NLCD class color 42\n",
    "    '85C77E', # Class 4 - Grass                 NLCD class color 41\n",
    "    '5475A8', # Class 5 -  water                 NLCD class color 11\n",
    "    'E8D1D1' # Class 5 -  developed             NLCD class color 21\n",
    "]\n",
    "\n",
    "  dem = ee.Image(\"USGS/NED\").select('elevation')\n",
    "  dsm = ee.Image(\"JAXA/ALOS/AW3D30/V2_2\").select('AVE_DSM')\n",
    "  buildings_canopy = dsm.subtract(dem) #.focal_min(radius=1)\n",
    "\n",
    "  # Less Than or equal to Lower\n",
    "  myMap.add_ee_layer(image.updateMask(image.lte(lowerQuartile)), {\"bands\":[band],\"palette\":[landcover_color_palette[0]],\"max\": lowerQuartile.getInfo()}, '%s Less Than or equal to Lower (road/highways)' % band)\n",
    "\n",
    "  # Less Than or equal to 10th\n",
    "  myMap.add_ee_layer(image.updateMask(image.lte(percentile10th)), {\"bands\":[band],\"palette\":[\"grey\"],\"max\": percentile10th.getInfo()}, '%s Less Than or equal to 10th (GREY) - Developed Imperious Road/Building/Asphalt' % band)\n",
    "\n",
    "  # Less Than median greater than lower\n",
    "  myMap.add_ee_layer(image.updateMask(image.gt(lowerQuartile).And(image.lt(median))), {\"bands\":[band],\"min\":lowerQuartile.getInfo(),\"max\":median.getInfo(),\"palette\":[landcover_color_palette[4]]}, '%s Less Than median greater than lower mask (GRASS)' % band)\n",
    "\n",
    "  # Greater Than Lower And Less than Upper\n",
    "  myMap.add_ee_layer(image.updateMask(image.gt(lowerQuartile).And(image.lt(upperQuartile))), {\"bands\":[band],\"min\":lowerQuartile.getInfo(),\"max\":upperQuartile.getInfo(),\"palette\":[landcover_color_palette[4]]}, '%s Greater Than Lower And Less than Upper (Grass/Forest)' % band)\n",
    "\n",
    "  # Greater Than median less than upper\n",
    "  myMap.add_ee_layer(image.updateMask(image.gt(median).And(image.lt(upperQuartile))), {\"bands\":[band],\"min\":median.getInfo(),\"max\":upperQuartile.getInfo(),\"palette\":[landcover_color_palette[3]]}, '%s Greater Than median less than upper mask (Forest Boundary)' % band) \n",
    "\n",
    "  # Greater Than or equal to Upper\n",
    "  myMap.add_ee_layer(image.updateMask(image.gte(upperQuartile)), {\"bands\":[band],\"palette\":[landcover_color_palette[3]],\"min\":upperQuartile.getInfo()}, '%s Greater Than or equal to Upper (Forest)' % band)\n",
    "\n",
    "  # Greater Than or equal to percentile90th\n",
    "  myMap.add_ee_layer(image.updateMask(image.gte(percentile90th)), {\"bands\":[band],\"palette\":[landcover_color_palette[3]],\"min\":percentile90th.getInfo()}, '%s Greater Than or equal to 90th (Forest)' % band)\n",
    "\n",
    "\n",
    "  # Grass DSM\n",
    "  myMap.add_ee_layer(image.updateMask(image.gt(lowerQuartile).And(buildings_canopy.lte(2))), {\"bands\":[band],\"min\":lowerQuartile.getInfo(),\"max\":upperQuartile.getInfo(),\"palette\":[landcover_color_palette[4]]}, '%s Grass with DSM)' % band)\n",
    "  # Forest DSM\n",
    "  myMap.add_ee_layer(image.updateMask(image.gt(lowerQuartile).And(buildings_canopy.gt(2))), {\"bands\":[band],\"min\":lowerQuartile.getInfo(),\"max\":upperQuartile.getInfo(),\"palette\":[landcover_color_palette[3]]}, '%s Forest with DSM)' % band)\n",
    "   \n",
    "  # Developed DSM\n",
    "  myMap.add_ee_layer(image.updateMask(image.lte(lowerQuartile).And(buildings_canopy.lte(3))), {\"bands\":[band],\"palette\":[landcover_color_palette[0]],\"max\": percentile10th.getInfo()}, '%s Developed with DSM' % band)\n",
    "\n",
    "  # Building DSM\n",
    "  myMap.add_ee_layer(image.updateMask(image.lte(lowerQuartile).And(buildings_canopy.gt(3))), {\"bands\":[band],\"palette\":[landcover_color_palette[1]],\"max\": percentile10th.getInfo()}, '%s Buildings with DSM' % band)\n",
    "\n",
    "  \n",
    " \n",
    "  myMap.add_child(folium.LayerControl())\n",
    "  display(myMap)\n",
    "  \n",
    "\n",
    "# quantileIndexes(ndbsvi, 'ndbsiv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "71UkoC76tozO",
    "outputId": "0c1afe1f-9717-45c9-c673-5e6cb16f2652"
   },
   "outputs": [],
   "source": [
    "quantileIndexes(ndvi.clipToCollection(aoi), 'ndvi', ['green','white', 'purple'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ShG81SP5Bkx"
   },
   "source": [
    "## Bare Earth Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiNhROcQi_JN"
   },
   "outputs": [],
   "source": [
    "bare_earth_feature_collection = bare_earth_vector.map(lambda f: f.set({\"landclass\": 2, \"landcover\": \"barren\"}))\n",
    "combined_feature_collection = sample_feature_collection.merge(bare_earth_feature_collection).map(lambda f: f.set(\"area\", f.area(0.001)));\n",
    "\n",
    "# Using Just OSM DATA\n",
    "# combined_feature_collection = sample_feature_collection.map(lambda f: f.set(\"area\", f.area(0.001)));\n",
    "\n",
    "# print(bare_earth_vector.getInfo())\n",
    "\n",
    "fc_list = combined_feature_collection.toList(count=1500).getInfo()\n",
    "list_of_properties = [f['properties'] for f in fc_list]\n",
    "df_combined_samples = pd.DataFrame(list_of_properties)\n",
    "\n",
    "# # Get a list of sample sizes\n",
    "# stratifed_samples_sizes = df_sample_stats['sample_size'].astype(int).values.tolist()\n",
    "\n",
    "# # Set water class to 0 because we will copy this data in after classification\n",
    "# stratifed_samples_sizes[5] = 0 # Remove Water\n",
    "# # stratifed_samples_sizes[2] = 19\n",
    "# # stratifed_samples_sizes[0] = 0 #roads added post classification\n",
    "\n",
    "# print(stratifed_samples_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhCTxrWCaAmX",
    "outputId": "9888e513-2f30-40f1-d162-91f505efc886"
   },
   "outputs": [],
   "source": [
    "df_sample_stats = df_combined_samples.groupby(['landcover','landclass'])['area'].describe().reset_index()\n",
    "df_sample_stats['area']= df_combined_samples.groupby(['landcover','landclass'])['area'].sum().values\n",
    "df_sample_stats.sort_values('landclass', inplace=True)\n",
    "print(df_sample_stats)\n",
    "#drop the roads row by index\n",
    "# df_sample_stats.drop(5, inplace=True) \n",
    "print(df_sample_stats[df_sample_stats['landclass'] == 2]['50%'].head(20))\n",
    "\n",
    "#Get min area\n",
    "min_area = df_sample_stats['area'].min()\n",
    "print(min_area)\n",
    "\n",
    "# calcluate the sample size by dividing the minmum total class area and dividing it by the median object area feature class.\n",
    "df_sample_stats['sample_size'] = df_sample_stats['50%'].apply(lambda x: int(min_area / x) if int(min_area / x) else 2, 1)\n",
    "\n",
    "df_sample_stats['median'] = df_sample_stats['50%']\n",
    "\n",
    "# Reformating for paper\n",
    "df_sample_stats[['landcover','count','min', 'median', 'sample_size']].set_index('landcover')\n",
    "# Get a list of sample sizes\n",
    "stratifed_samples_sizes = df_sample_stats['sample_size'].astype(int).values.tolist()\n",
    "\n",
    "# Set water class to 0 because we will copy this data in after classification\n",
    "#stratifed_samples_sizes[5] = 0 # Remove Water\n",
    "# stratifed_samples_sizes[2] = 19\n",
    "# stratifed_samples_sizes[0] = 0 #roads added post classification\n",
    "\n",
    "print(stratifed_samples_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3GaMdnGi2Bd",
    "outputId": "bedf57bc-d565-4184-ced9-7996820490c2"
   },
   "outputs": [],
   "source": [
    "# Get a list of sample sizes\n",
    "stratifed_samples_sizes = df_sample_stats['sample_size'].astype(int).values.tolist()\n",
    "\n",
    "# Set water class to 0 because we will copy this data in after classification\n",
    "#stratifed_samples_sizes[5] = 0 # Remove Water\n",
    "# stratifed_samples_sizes[2] = 19\n",
    "# stratifed_samples_sizes[0] = 0 #roads added post classification\n",
    "\n",
    "print(stratifed_samples_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Ye6qkAmhbBWJ",
    "outputId": "a5618097-e132-43c8-b146-799cb738fbfa"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.set_xscale(\"log\")\n",
    "df_combined_samples['area_km'] = df_combined_samples['area'].apply(lambda x: x / 1e6)\n",
    "# df_combined_samples =  df_combined_samples[df_combined_samples['landcover'] != 'road']\n",
    "# Plot the orbital period with horizontal boxes\n",
    "sns.boxplot(x=\"area\", y=\"landcover\", data=df_combined_samples.sort_values('landclass'),\n",
    "            whis=[0, 100],palette=sns.color_palette(['#B50000','#D2CDC0', '#38814E','#85C77E', '#E8D1D1']))\n",
    "\n",
    "# Add in points to show each observation\n",
    "sns.stripplot(x=\"area\", y=\"landcover\", data=df_combined_samples.sort_values('landclass'),\n",
    "              size=2, color=\".3\", linewidth=0, dodge=True)\n",
    "\n",
    "# Tweak the visual presentation\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"\")\n",
    "ax.set_xlabel(\"Area m2\",fontsize=16 )\n",
    "ax.tick_params(labelsize=16)\n",
    "sns.despine(trim=True, left=True)\n",
    "# ax.axvline(x=df_sample_stats[df_sample_stats['landcover'] == 'road']['50%'].values, linewidth=1, color=\"#\"+landcover_color_palette[0],linestyle=\"--\", label=\"Road\")\n",
    "# ax.axvline(x=df_sample_stats[df_sample_stats['landcover'] == 'building']['50%'].values, linewidth=1, color=\"#\"+landcover_color_palette[1],linestyle=\"--\", label=\"Building\")\n",
    "# ax.axvline(x=df_sample_stats[df_sample_stats['landcover'] == 'barren']['50%'].values, linewidth=1, color=\"#\"+landcover_color_palette[2],linestyle=\"--\", label=\"Barren\")\n",
    "# ax.axvline(x=df_sample_stats[df_sample_stats['landcover'] == 'forest']['50%'].values, linewidth=1, color=\"#\"+landcover_color_palette[3],linestyle=\"--\", label=\"Forest\")\n",
    "# ax.axvline(x=df_sample_stats[df_sample_stats['landcover'] == 'grass']['50%'].values, linewidth=1, color=\"#\"+landcover_color_palette[4],linestyle=\"--\", label=\"Grass\")\n",
    "# ax.axvline(x=df_sample_stats[df_sample_stats['landcover'] == 'water']['50%'].values, linewidth=1, color=\"#\"+landcover_color_palette[5],linestyle=\"--\", label=\"Water\")\n",
    "plt.title('Land Cover Samples', fontsize=24) \n",
    "# landcover_color_palette = [\n",
    "#     'E29E8C', # Class 0 - road/highways         NLCD class color 22\n",
    "#     'B50000', # Class 1 - Building dark red     NLCD class color 24\n",
    "#     'D2CDC0', # Class 2 - barren                NLCD class color 31\n",
    "#     '38814E', # Class 3 - Forest                NLCD class color 42\n",
    "#     '85C77E', # Class 4 - Grass                 NLCD class color 41\n",
    "#     '5475A8', # Class 5 -  water                 NLCD class color 11\n",
    "#     'E8D1D1' # Class 5 -  developed             NLCD class color 21\n",
    "# ]\n",
    "\n",
    "plt.savefig(os.path.join(figures_save_location,\"Samples Box Area Plot\"),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dojygnkhhH83"
   },
   "outputs": [],
   "source": [
    "# df_sample_stats.rename(columns=['count', 'mean', 'median', 'area', 'sample_size']).set_index('landcover')[['count', 'mean', '50%', 'area', 'sample_size (median)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAyYE8pNd6sm"
   },
   "outputs": [],
   "source": [
    "classes_w_barren = ee.Image().byte().paint(combined_feature_collection, \"landclass\").rename(\"landclass\").where(\n",
    "    classes.eq(5).selfMask(), 5).where(\n",
    "        classes.eq(0).selfMask(), 0).where(\n",
    "            classes.eq(1).selfMask(), 1\n",
    "        )\n",
    "\n",
    "#classes_w_barren = classes.where(bare_earth_samples.eq(2).And(classes.Not()), 2).clipToCollection(aoi_bbox)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHcxEP_BGMbe"
   },
   "source": [
    "## Outlire Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "1IZXSYA6GS1y",
    "outputId": "8ca45ba2-99cc-4801-de7e-52d91cd89e8a"
   },
   "outputs": [],
   "source": [
    "#https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/9ZIUGQ\n",
    "\n",
    "def detectOutlires(image, band, scale=3, region=aoi):\n",
    "  # // Tukey's lower and upper fence\n",
    "  percentiles = image.reduceRegion(\n",
    "      reducer=ee.Reducer.percentile([10,25,50,75,90]),\n",
    "      geometry=region,\n",
    "      scale=scale,\n",
    "      maxPixels= 1e12)\n",
    "  \n",
    "  lowerQuartile = ee.Number(percentiles.get(band+'_p25'))\n",
    "  median = ee.Number(percentiles.get(band+'_p50'))\n",
    "  upperQuartile = ee.Number(percentiles.get(band+'_p75'))\n",
    "\n",
    "  IQR = upperQuartile.subtract(lowerQuartile)\n",
    "  lowerFence = lowerQuartile.subtract(IQR.multiply(1.5))\n",
    "  upperFence = upperQuartile.add(IQR.multiply(1.5))\n",
    "  \n",
    "  quartiles = image.gt(lowerQuartile).add(image.gt(median)).add(image.gt(upperQuartile)).remap([0,1,2,3],[1,2,3,4]).rename('quartile')\n",
    "  outliers = image.gt(lowerFence).add(image.gt(upperFence)).remap([0,1,2],[1,0,2])\n",
    "  tukeys = outliers.updateMask(outliers.neq(0)).rename('fence')\n",
    "  \n",
    "  # // Z-score\n",
    "  mean = ee.Number(image.reduceRegion(\n",
    "      reducer= ee.Reducer.mean(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get(band))\n",
    "\n",
    "  stdDev = ee.Number(image.reduceRegion(\n",
    "      reducer= ee.Reducer.stdDev(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get(band));\n",
    "  \n",
    "  zScore = image.subtract(mean).divide(stdDev).rename('zscore')\n",
    "  \n",
    "  # // Modified Z-score\n",
    "  medAbsDev = image.subtract(median).abs();\n",
    "  \n",
    "  medianMedAbsDev = ee.Number(medAbsDev.reduceRegion(\n",
    "      reducer= ee.Reducer.median(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get(band))\n",
    "  \n",
    "  zScoreMod = image.subtract(mean).multiply(0.6745).divide(medianMedAbsDev).abs().rename('zscore_mod')\n",
    "  zScoreModExp = zScoreMod.gt(3.5).multiply(3)\n",
    "  zScoreModOutliers = zScoreModExp.updateMask(zScoreModExp.eq(3)).rename('zmod_outlier')\n",
    "  \n",
    "  # // Lower fence/upper fance + modified s-score outliers\n",
    "  combined = zScoreModExp.add(outliers).rename('combined_outliers').remap([0,1,2,3,4,5],[0,3,4,5,1,2])\n",
    "                #  // 0 = none\n",
    "                #  // 1 = lower fence\n",
    "                #  // 2 = upper fence\n",
    "                #  // 3 = modified z-score\n",
    "                #  // 4 = lower fence + modified z-score\n",
    "                #  // 5 = upper fence + modified z-score \n",
    "  combinedMask = combined.updateMask(combined.neq(0))\n",
    "      \n",
    "  # // Geary's C statistic\n",
    "  clist = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "  centerList = [1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
    "  lists = [clist, clist, clist, clist, centerList, clist, clist, clist, clist]\n",
    "  kernel = ee.Kernel.fixed(9, 9, lists, -4, -4, False)\n",
    "  neighs = image.neighborhoodToBands(kernel)\n",
    "  # import math\n",
    "  gearys = image.subtract(neighs).pow(2).reduce(ee.Reducer.sum()).divide(9**2)\n",
    "         \n",
    "  gearysQuartiles = gearys.reduceRegion(\n",
    "      reducer=ee.Reducer.percentile([10,25,75,90]),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12)\n",
    "  \n",
    "  # gearys10 = gearysQuartiles.get('sum_p10').getInfo()\n",
    "  # print(gearys10)\n",
    "\n",
    "  gearysLowerQuartile = ee.Number(gearysQuartiles.get('sum_p25'))\n",
    "  # print(gearysLowerQuartile)\n",
    "  gearysUpperQuartile = ee.Number(gearysQuartiles.get('sum_p75'))\n",
    "  gearysIQR = gearysUpperQuartile.subtract(gearysLowerQuartile)\n",
    "  gearysUpperFence = gearysUpperQuartile.add(gearysIQR.multiply(1.5))\n",
    "  gearysAccum = gearys.gt(gearysUpperFence).rename('gearys_outlier')\n",
    "  print('gearysAccum')\n",
    "  gearysOutlier = gearysAccum.updateMask(gearysAccum.eq(1)).rename('spatial_outlier')\n",
    "  print('gearysOutlier')\n",
    "  \n",
    "  # // Locate pixels â¤ zero\n",
    "  lteZero = image.lte(0).updateMask(image.lte(0).eq(1))\n",
    "  print('lteZero')\n",
    "\n",
    "  # // Layer design values\n",
    "  zScorePercentiles = zScore.reduceRegion(\n",
    "      reducer=ee.Reducer.percentile([10,90]),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12)\n",
    "  print('zScorePercentiles')\n",
    "\n",
    "  zScoreModPercentiles = zScoreMod.reduceRegion(\n",
    "      reducer=ee.Reducer.percentile([10,90]),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12)\n",
    "  \n",
    "  print('zScoreModPercentiles')\n",
    "\n",
    "  raw10 = ee.Number(percentiles.get(band+'_p10')).getInfo()\n",
    "  print('raw10')\n",
    "  raw90 = ee.Number(percentiles.get(band+'_p90')).getInfo()\n",
    "  print('raw90')\n",
    "  zScore10 = ee.Number(zScorePercentiles.get('zscore_p10')).getInfo()\n",
    "  print('zScore10')\n",
    "  zScore90 = ee.Number(zScorePercentiles.get('zscore_p90')).getInfo()\n",
    "  print('zScore90')\n",
    "  zScoreMod10 = ee.Number(zScoreModPercentiles.get('zscore_mod_p10')).getInfo()\n",
    "  print('zScoreMod10')\n",
    "  zScoreMod90 = ee.Number(zScoreModPercentiles.get('zscore_mod_p90')).getInfo()\n",
    "  print('zScoreMod90')\n",
    "  gearys10 = ee.Number(gearysQuartiles.get('sum_p10')).getInfo()\n",
    "  print('gearys10')\n",
    "  gearys90 = ee.Number(gearysQuartiles.get('sum_p90')).getInfo()\n",
    "  print('gearys90')\n",
    "\n",
    "  \n",
    " \n",
    "  # -- Make sure to change the scale to calculate accurate area percentages\n",
    "  print(\"AreaImage Start\")\n",
    "  areaImage = image.multiply(0).rename('area')\n",
    "  print(\"AreaImage End\")\n",
    "  totalArea = ee.Number(areaImage.add(1).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area'))\n",
    "\n",
    "  print(\"totalArea\")\n",
    "\n",
    "  lfmzArea = ee.Number(areaImage.add(combinedMask.eq(1)).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area')).divide(totalArea).multiply(100).getInfo() #.toFixed(2) #round(a, 2)\n",
    "  print(\"lfmzArea\")\n",
    "  ufmzArea = ee.Number(areaImage.add(combinedMask.eq(2)).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area')).divide(totalArea).multiply(100).getInfo() #.toFixed(2)\n",
    "  print(\"ufmzArea\")\n",
    "  lfArea = ee.Number(areaImage.add(tukeys.eq(1)).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area')).divide(totalArea).multiply(100).getInfo() #.toFixed(2)\n",
    "  print(\"lfArea\")\n",
    "\n",
    "  ufArea = ee.Number(areaImage.add(tukeys.eq(2)).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area')).divide(totalArea).multiply(100).getInfo() #.toFixed(2)\n",
    "  print(\"ufArea\")\n",
    "\n",
    "  mzArea = ee.Number(areaImage.add(zScoreModOutliers.eq(3)).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area')).divide(totalArea).multiply(100).getInfo() #.toFixed(2)\n",
    "  \n",
    "  lteZeroArea = ee.Number(areaImage.add(lteZero.eq(0)).reduceRegion(\n",
    "      reducer= ee.Reducer.sum(),\n",
    "      geometry= region,\n",
    "      scale= scale,\n",
    "      maxPixels= 1e12).get('area')).divide(totalArea).multiply(100).getInfo() #.toFixed(2)\n",
    "\n",
    "  # center_map = [region.centroid().getInfo()['coordinates'][1],region.centroid().getInfo()['coordinates'][0]]\n",
    "  # Create a folium map object.\n",
    "  myMap = folium.Map(location=center_map, zoom_start=13, height=500)\n",
    "\n",
    "  # // Add layers to display\n",
    "  grayscale = ['f7f7f7', 'cccccc', '969696', '525252'];\n",
    "\n",
    "  myMap.add_ee_layer(image, {'min': raw10, 'max': raw90, 'palette': grayscale}, 'version')\n",
    "\n",
    "  \n",
    "  myMap.add_ee_layer(quartiles, {'min': 1, 'max': 4, 'palette': grayscale}, 'Quartiles')\n",
    "\n",
    "\n",
    "  myMap.add_ee_layer(zScore, {'min': zScore10, 'max': zScore90, 'palette': grayscale}, 'Z-score')\n",
    "\n",
    " \n",
    "  myMap.add_ee_layer(zScoreMod, {'min': zScoreMod10, 'max': zScoreMod90, 'palette': grayscale}, 'Modified Z-score')\n",
    "\n",
    "  myMap.add_ee_layer(gearys, {'min': gearys10, 'max': gearys90, 'palette': grayscale}, \"Geary's C\")\n",
    "\n",
    " \n",
    "  myMap.add_ee_layer(tukeys, {'min': 1, 'max': 2, 'palette': ['22a6ff','ffd400']}, \"Tukey's outliers\")\n",
    "\n",
    " \n",
    "  myMap.add_ee_layer(zScoreModOutliers, {'min': 3, 'max': 3, 'palette': '13e864'}, 'Modified Z-score outlier')\n",
    "\n",
    "  myMap.add_ee_layer(gearysOutlier, {'min': 1, 'max': 1, 'palette': ['bebebe']}, \"Geary's C design layer\")\n",
    "  myMap.add_ee_layer(gearysOutlier, {'min': 1, 'max': 1, 'palette': ['bebebe']}, \"Geary's C outlier\")\n",
    "  myMap.add_ee_layer(combinedMask, {'min': 1, 'max': 5, 'palette': ['6713e8','ff225a','22a6ff','ffd400','13e864']}, 'Combined outliers')\n",
    "\n",
    "  # Map.addLayer(lteZero, {min: 0, max: 0, palette: ['202020']}, 'Pixel â¤ zero', false);\n",
    "  myMap.add_ee_layer(lteZero, {'min': 0, 'max': 0, 'palette': ['202020']}, 'Pixel lte zero')\n",
    "\n",
    "  # empty = ee.Image().byte();\n",
    "  # var regionVis = empty.paint({\n",
    "  #   featureCollection: region,\n",
    "  #   width: 3\n",
    "  # });\n",
    "  # Map.addLayer(regionVis, {palette: '252525'}, regionName);\n",
    "  # Map.centerObject(region);\n",
    "  myMap.add_child(folium.LayerControl())\n",
    "\n",
    "  # Display the map.\n",
    "  display(myMap)\n",
    "\n",
    "detectOutlires(before_image.select('b1'),'b1',scale=30)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QQs8VoEvSXd"
   },
   "outputs": [],
   "source": [
    "detectOutlires(before_image.select('b4'),'b4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "2u7Of00tCGJN",
    "outputId": "7cf90855-daa4-45b6-c50f-8e41dd1ba59b"
   },
   "outputs": [],
   "source": [
    "# Set visualization parameters.\n",
    "visParams = {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}\n",
    "\n",
    "# Get AOI centroid\n",
    "center_map =  aoi.geometry().centroid().getInfo()['coordinates'].reverse() #[aoi.centroid().getInfo()['coordinates'][1],aoi.centroid().getInfo()['coordinates'][0]]\n",
    "\n",
    "# Create a folium map object.\n",
    "myMap = folium.Map(location=center_map, zoom_start=13, height=500)\n",
    "\n",
    "# Add the elevation model to the map object.\n",
    "planet_scope_mosaic = planet_scope.median()\n",
    "mapID = ee.Image(planet_scope_mosaic).getMapId(visParams)\n",
    "myMap.add_ee_layer(planet_scope_mosaic, visParams, 'PlanetScope Mosaic')\n",
    "\n",
    "\n",
    "myMap.add_ee_layer(before_image, visParams, 'April')\n",
    "myMap.add_ee_layer(after_image, visParams, 'May')\n",
    "analog_nir = before_image.select('b4').addBands(after_image.select('b4'))\n",
    "analog_red = before_image.select('b3').addBands(after_image.select('b3'))\n",
    "analog_blue = before_image.select('b2').addBands(after_image.select('b2'))\n",
    "analog_green = before_image.select('b1').addBands(after_image.select('b1'))\n",
    "analog_ndvi = createNDVI(before_image).select('ndvi').addBands(createNDVI(after_image).select('ndvi'))\n",
    "analog_bsi = createBSI(before_image).select('bsi').addBands(createBSI(after_image).select('bsi'))\n",
    "\n",
    "\n",
    "nir_min_max = analog_nir.reduceRegion(reducer=ee.Reducer.minMax(),geometry=aoi,scale=3,maxPixels= 1e12)\n",
    "print(nir_min_max.getInfo())\n",
    "nir_min = ee.Number(nir_min_max.get(\"b4_1_min\"))\n",
    "nir_max = ee.Number(nir_min_max.get(\"b4_1_max\"))\n",
    "\n",
    "myMap.add_ee_layer(analog_nir, {\"bands\": [\"b4\",\"b4_1\",\"b4_1\"], \"min\":nir_min, \"max\":nir_max}, 'Analog NIR')\n",
    "\n",
    "analog_red_min_max = analog_red.reduceRegion(reducer=ee.Reducer.minMax(),geometry=aoi,scale=3,maxPixels= 1e12)\n",
    "print(analog_red_min_max.getInfo())\n",
    "analog_red_min = ee.Number(analog_red_min_max.get(\"b3_1_min\"))\n",
    "analog_red_max = ee.Number(analog_red_min_max.get(\"b3_1_max\"))\n",
    "\n",
    "myMap.add_ee_layer(analog_red, {\"bands\": [\"b3\", \"b3_1\", \"b3_1\"], \"min\":analog_red_min, \"max\":analog_red_max}, 'Analog B3 Red')\n",
    "\n",
    "analog_blue_min_max = analog_blue.reduceRegion(reducer=ee.Reducer.minMax(),geometry=aoi,scale=3,maxPixels= 1e12)\n",
    "print(analog_blue_min_max.getInfo())\n",
    "analog_blue_min = ee.Number(analog_blue_min_max.get(\"b2_1_min\"))\n",
    "analog_blue_max = ee.Number(analog_blue_min_max.get(\"b2_1_max\"))\n",
    "myMap.add_ee_layer(analog_blue, {\"bands\": [\"b2\", \"b2_1\", \"b2_1\"], \"min\":analog_blue_min, \"max\":analog_blue_max}, 'Analog B2 Blue')\n",
    "\n",
    "\n",
    "myMap.add_ee_layer(analog_green, {\"bands\": [\"b1\", \"b1_1\", \"b1_1\"], \"min\":326, \"max\":4233}, 'Analog B1 Green')\n",
    "\n",
    "\n",
    "analog_ndvi_min_max = analog_ndvi.reduceRegion(reducer=ee.Reducer.minMax(),geometry=aoi,scale=3,maxPixels= 1e12)\n",
    "print(analog_ndvi_min_max.getInfo())\n",
    "analog_ndvi_min = ee.Number(analog_ndvi_min_max.get(\"ndvi_1_min\"))\n",
    "analog_ndvi_max = ee.Number(analog_ndvi_min_max.get(\"ndvi_1_max\"))\n",
    "myMap.add_ee_layer(analog_ndvi, {\"bands\": [\"ndvi\", \"ndvi_1\", \"ndvi_1\"], \"min\":analog_ndvi_min, \"max\":analog_ndvi_max}, 'Analog NDVI')\n",
    "\n",
    "analog_bsi_min_max = analog_bsi.reduceRegion(reducer=ee.Reducer.minMax(),geometry=aoi,scale=3,maxPixels= 1e12)\n",
    "print(analog_bsi_min_max.getInfo())\n",
    "analog_bsi_min = ee.Number(analog_bsi_min_max.get(\"bsi_1_min\"))\n",
    "analog_bsi_max = ee.Number(analog_bsi_min_max.get(\"bsi_1_max\"))\n",
    "myMap.add_ee_layer(analog_bsi, {\"bands\": [\"bsi\", \"bsi_1\", \"bsi_1\"], \"min\":analog_bsi_min, \"max\":analog_bsi_max}, 'Analog BSI')\n",
    "\n",
    "# Add study area markers\n",
    "# folium.GeoJson(cary_park.toGeoJSON()).add_to(myMap)\n",
    "# folium.GeoJson(centenial.toGeoJSON()).add_to(myMap)\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mihJblDGatIt"
   },
   "source": [
    "## Generate Change Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "Rx8c39vnayIE",
    "outputId": "fcc8b4f4-7da6-48cc-991d-b892e1b1d593"
   },
   "outputs": [],
   "source": [
    "water_mask = ps_median.where(classes.eq(5), -9999).neq(-9999).select('b3').selfMask()\n",
    "\n",
    "\n",
    "binary_red_change = before_image.select('b3').subtract(after_image.select('b3'))#.updateMask(water_mask)\n",
    "binary_reducer = ee.Reducer.mean().combine(reducer2 = ee.Reducer.stdDev(), sharedInputs=True)\n",
    "\n",
    "binary_red_std = binary_red_change.reduceRegion(reducer=binary_reducer, geometry=aoi.geometry(),scale=30,maxPixels= 1e12)\n",
    "\n",
    "neg_3std = binary_red_std.get('b3_mean').getInfo() + (binary_red_std.get('b3_stdDev').getInfo() * -2.5)\n",
    "\n",
    "red_change_mask = binary_red_change.focal_min(1).lte(neg_3std).selfMask()\n",
    "\n",
    "sample_mask = binary_red_change.focal_min(1).gt(neg_3std).selfMask()\n",
    "\n",
    "myMap = folium.Map(location=center_map, zoom_start=15, height=900)\n",
    "\n",
    "for layer in ps_collection_obcd:\n",
    "  myMap.add_ee_layer(ps_collection_obcd[layer], {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}, \"PS %s\" % layer)\n",
    "\n",
    "myMap.add_ee_layer(red_change_mask, {\"palette\": ['red'], 'opacity': 0.8}, 'Red Change Mask')\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97OfKOeSzXfW"
   },
   "outputs": [],
   "source": [
    "quantileIndexes(binary_red_change, 'b3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "O4FQtbp6XDnF",
    "outputId": "79d9334a-87b7-473b-c3ba-ec90f4941ddc"
   },
   "outputs": [],
   "source": [
    "detectOutlires(binary_red_change, 'b3', scale=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJSpGVtJTd-9"
   },
   "outputs": [],
   "source": [
    "detectOutlires(binary_nir_change, 'b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "QXIKVg2yq8AV",
    "outputId": "0b6bd382-afd9-466e-cc48-407465dd7614"
   },
   "outputs": [],
   "source": [
    "objectId = red_change_mask.connectedComponents(ee.Kernel.plus(1), 128)\n",
    "# objectId128 = red_change_mask.connectedComponents(ee.Kernel.plus(1), 128)\n",
    "# Compute the number of pixels in each object defined by the \"labels\" band.\n",
    "objectSize = objectId.select('labels').connectedPixelCount(128,False)\n",
    "# Get a pixel area image.\n",
    "pixelArea = ee.Image.pixelArea()\n",
    "# Multiply pixel area by the number of pixels in an object to calculate\n",
    "# the object area. The result is an image where each pixel\n",
    "# of an object relates the area of the object in m^2.\n",
    "objectArea = objectSize.multiply(pixelArea)\n",
    "# Map.addLayer(objectArea, null, 'objectArea');\n",
    "\n",
    "## Threshold the `objectArea` image to define a mask that will mask out\n",
    "areaMask = objectArea.gte(1000);\n",
    "\n",
    "# Update the mask of the `objectId` layer defined previously using the\n",
    "# minimum area mask just defined.\n",
    "change_locations = objectId.updateMask(areaMask)\n",
    "\n",
    "myMap = folium.Map(location=center_map, zoom_start=15, height=900)\n",
    "\n",
    "for layer in ps_collection_obcd:\n",
    "  myMap.add_ee_layer(ps_collection_obcd[layer], {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}, \"PS %s\" % layer)\n",
    "\n",
    "# myMap.add_ee_layer(objectId128.randomVisualizer(), {'opacity': 0.75}, 'objectId128')\n",
    "\n",
    "myMap.add_ee_layer(change_locations.randomVisualizer(), {'opacity': 0.75}, 'Change Locations')\n",
    "\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEvasLq6_LtJ"
   },
   "source": [
    "Remove Samples from change pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "uA9kUtDe_IKC",
    "outputId": "30fff515-970c-4098-dc3d-cc67c7e2b8a4"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Switch Back to OSM classes because the bearren class was acting up\n",
    "classes_w_barren_change_mask = classes_w_barren.updateMask(sample_mask)\n",
    "# Get AOI centroid\n",
    "\n",
    "# Create a folium map object.\n",
    "myMap = folium.Map(location=center_map, zoom_start=14, height=500)\n",
    "\n",
    "# Add the elevation model to the map object.\n",
    "planet_scope_mosaic = planet_scope.median()\n",
    "\n",
    "planet_scope_mosaic_log = planet_scope.median().log()\n",
    "planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "myMap.add_ee_layer(planet_scope_mosaic_log, planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "\n",
    "\n",
    "myMap.add_ee_layer(change_locations.randomVisualizer().updateMask(red_change_mask), {'opacity': 0.75}, 'Change Locations')\n",
    "\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZFlmf6aId7V"
   },
   "source": [
    "\n",
    "\n",
    "## Explore Segmentation Cluster Params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "prwMaWqlhS-q",
    "outputId": "9f1a15b6-8455-49b7-befb-4d6453975861"
   },
   "outputs": [],
   "source": [
    "myMap = folium.Map(location=center_map, zoom_start=16, height=900)\n",
    "\n",
    "\n",
    "myMap.add_ee_layer(ps_median, {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}, \"PS %s\" % layer)\n",
    "\n",
    "cluster_sizes = [10, 15, 20, 25, 30,35,40,50,100]\n",
    "\n",
    "for size in cluster_sizes:\n",
    "    print(\"Size: %s, Neighborhood: %s\" % (size, size * 2))\n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(size); #8 was good # 5\n",
    "    compactness = [0.8]\n",
    "    for c in compactness:\n",
    "      # Run SNIC on the regular square grid.\n",
    "      snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
    "          size=size,\n",
    "          image= ps_median, \n",
    "          compactness= c, # was 5\n",
    "          connectivity= 8, # was 8\n",
    "          neighborhoodSize=size*4, #16was 3,\n",
    "          seeds= seeds\n",
    "        )\n",
    "\n",
    "      snic = snic.select(['b1_mean', 'b2_mean', 'b3_mean', 'b4_mean', 'clusters'], ['b1', 'b2', 'b3', 'b4', 'clusters'])\n",
    "\n",
    "      clusters = snic.select('clusters')\n",
    "      myMap.add_ee_layer(clusters.randomVisualizer(), None, 'Cluster %s, Compactness %s' % (size,c))\n",
    "# train = ps_median.sample(aoi)\n",
    "# test_seg_classifier = ee.Clusterer.wekaCascadeKMeans().train(train,inputProperties=ps_median.bandNames().getInfo())\n",
    "# unsup_seg = ps_median.cluster(test_seg_classifier)\n",
    "# myMap.add_ee_layer(unsup_seg.randomVisualizer(), None, 'Unsupervised Image Seg')\n",
    "\n",
    "# buildings = classes.select('landclass').eq(1).selfMask()\n",
    "# myMap.add_ee_layer(buildings, {\"palette\":['grey']}, 'Buildings')\n",
    "\n",
    "\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNhEwgeUbY3x"
   },
   "source": [
    "## Building and Canopy Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "id": "WnQYSKQGbYC-",
    "outputId": "f39322ac-d5ed-4fb8-c479-15fcfb7a2278"
   },
   "outputs": [],
   "source": [
    "dem = ee.Image(\"USGS/NED\").select('elevation')\n",
    "dsm = ee.Image(\"JAXA/ALOS/AW3D30/V2_2\").select('AVE_DSM')\n",
    "buildings_canopy = dsm.subtract(dem)#.addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256).rename('object_height')\n",
    "\n",
    "# Create a folium map object.\n",
    "myMap = folium.Map(location=center_map, zoom_start=12, height=500)\n",
    "\n",
    "# Add the elevation model to the map object.\n",
    "planet_scope_mosaic = planet_scope.median()\n",
    "\n",
    "planet_scope_mosaic_log = planet_scope.median().log()\n",
    "planet_scope_mosaic_vis_params = {\"bands\": ['b3','b2','b1'], 'min':5.67, 'max': 8.39}\n",
    "myMap.add_ee_layer(planet_scope_mosaic_log.updateMask(aoi_mask), planet_scope_mosaic_vis_params, 'PlanetScope Log Median')\n",
    "\n",
    "myMap.add_ee_layer(buildings_canopy.updateMask(aoi_mask), {\"min\": 1, \"palette\": ['red','orange','yellow', 'purple','lime', 'green'], \"opacity\": 0.7}, \"Building and Canopy\")\n",
    "myMap.add_ee_layer( ps_collection_obcd[\"before\"], planet_scope_mosaic_vis_params, 'PlanetScope Before')\n",
    "\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-Mv04Mt8Ew4"
   },
   "source": [
    "## Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gU82OnDx3Pb"
   },
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/273658/performing-object-based-image-classification-in-google-earth-engine\n",
    "ps_collection_obcd_classified = {}\n",
    "ps_collection_obcd_metrics = {}\n",
    " \n",
    "def classifyImage(image, aoi, scale=3):\n",
    "# for image in ps_collection_obcd:\n",
    "  print(\"Lable: \" + image)\n",
    "  image_label = image\n",
    "  geometry = aoi\n",
    "  scale = scale \n",
    "\n",
    "  bands = ['b1', 'b2', 'b3', 'b4']\n",
    "\n",
    "  # Covert 16-bit unsigned integer to 8-bit unsigned\n",
    "  img = ps_collection_obcd[image].select(bands)\n",
    "  size = 30\n",
    "  #seeds = ee.Algorithms.Image.Segmentation.seedGrid(size); #8 was good # 5\n",
    "\n",
    "  # Run SNIC on the regular square grid.\n",
    "  #snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
    "  #  image= img, \n",
    "  #  compactness= 0.8, # was 5\n",
    "   # connectivity= 8, # was 8\n",
    "  #  neighborhoodSize=int(size*5), #16was 3,\n",
    "  #  seeds= seeds\n",
    "  #)\n",
    "\n",
    "  #snic = snic.select(['b1_mean', 'b2_mean', 'b3_mean', 'b4_mean', 'clusters'], ['b1', 'b2', 'b3', 'b4', 'clusters'])\n",
    "\n",
    "  #clusters = snic.select('clusters')\n",
    "\n",
    "\n",
    "  # Compute per-cluster stdDev.\n",
    "  #stdDev = img.addBands(clusters).reduceConnectedComponents(ee.Reducer.stdDev(), 'clusters', 256)\n",
    "\n",
    "  \n",
    "  ndviMedian = createNDVI(img) #.addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256)\n",
    "  ndwiMedian = createNDWI(img)#.addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256)\n",
    "  bsiMedian = createBSI(img)#.addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256)\n",
    "  # dsbiMedian = createDSBI(img).addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256)\n",
    "\n",
    "  # Low pass filter\n",
    "  medianPixel = img.reduceNeighborhood(reducer=ee.Reducer.median(), kernel=ee.Kernel.square(5))\n",
    "  stdPixel = img.reduceNeighborhood(reducer=ee.Reducer.stdDev(), kernel=ee.Kernel.square(5))\n",
    "  minMax = img.reduceNeighborhood(reducer=ee.Reducer.minMax(), kernel=ee.Kernel.square(5))\n",
    "  # canny = ee.Algorithms.CannyEdgeDetector(image=img, threshold= 10, sigma= 1)\n",
    "  # hough = ee.Algorithms.HoughTransform(canny, 256, 600, 100)\n",
    "  # ndbsivMedian = createBSI_NDVI_index(bsiMedian.select('bsi'),ndviMedian.select('ndvi')).addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256)\n",
    "  # laplacian8 = ee.Kernel.laplacian8(magnitude, normalize)\n",
    "  glcm_nir = img.select('b3')\n",
    "  # GLCM only works on Images 32bit and lower\n",
    "  glcm = glcm_nir.toInt32().glcmTexture(size=3)#.addBands(clusters).reduceConnectedComponents(ee.Reducer.median(), 'clusters',256)\n",
    "\n",
    "\n",
    "\n",
    "  #Area, Perimeter, Width and Height\n",
    "  #area = ee.Image.pixelArea().addBands(clusters).reduceConnectedComponents(ee.Reducer.sum(), 'clusters', 256)\n",
    "  \n",
    "  \n",
    "  #minMax = clusters.reduceNeighborhood(ee.Reducer.minMax(), ee.Kernel.square(1));\n",
    "  \n",
    "  #perimeterPixels = minMax.select(0).neq(minMax.select(1)).rename('perimeter');\n",
    "\n",
    "  \n",
    "  #perimeter = perimeterPixels.addBands(clusters).reduceConnectedComponents(ee.Reducer.sum(), 'clusters', 256);\n",
    "  \n",
    "\n",
    "  #sizes = ee.Image.pixelLonLat().addBands(clusters).reduceConnectedComponents(ee.Reducer.minMax(), 'clusters', 256)\n",
    "  #width = sizes.select('longitude_max').subtract(sizes.select('longitude_min')).rename('width')\n",
    "  #height = sizes.select('latitude_max').subtract(sizes.select('latitude_min')).rename('height')\n",
    "\n",
    "  #gives metrics of shape smoothness (low) or roughtness (high)\n",
    "  #shape_index = perimeter.divide(area.sqrt().multiply(4)) #Chapter 9 p.419 IDIP\n",
    "  \n",
    "  objectPropertiesImage = ee.Image.cat([\n",
    "    img.select(['b1', 'b4']),\n",
    "    medianPixel.select(['b1_median', 'b4_median']),\n",
    "    stdPixel.select(['b1_stdDev','b4_stdDev']),\n",
    "    # hough,\n",
    "    minMax.select(['b1_min','b1_max', 'b4_min', 'b4_max']),\n",
    "    # stdDev.select(['b3', 'b4']),\n",
    "    ndviMedian.select('ndvi'),\n",
    "    ndwiMedian.select('ndwi'),\n",
    "    # dsbiMedian.select('dsbi'),\n",
    "    bsiMedian.select('bsi'),\n",
    "    # ndbsivMedian.select('ndbsiv'),\n",
    "    glcm.select('b3_contrast', 'b3_asm', 'b3_corr'),\n",
    "    # area,\n",
    "    # perimeter,\n",
    "    # width,\n",
    "    # height,\n",
    "    # shape_index\n",
    "    # buildings_canopy.clipToCollection(aoi)\n",
    "  ]).float();\n",
    "  print(\"objects properties image created\")\n",
    "\n",
    "  #Mean center the data to enable a faster covariance reducer\n",
    "  #and an SD stretch of the principal components.\n",
    "  bandNames = objectPropertiesImage.bandNames().getInfo()\n",
    "  meanDict = objectPropertiesImage.reduceRegion(reducer= ee.Reducer.mean(), geometry = geometry, scale=scale, maxPixels=1e12, bestEffort=True, tileScale=16)\n",
    "  means = ee.Image.constant(meanDict.values(bandNames))\n",
    "  centered = objectPropertiesImage.subtract(means);\n",
    "  print(\"PCA:\")\n",
    "  # pcImage = getPrincipalComponents(objectPropertiesImage, scale, geometry).float()\n",
    "  pcImage = objectPropertiesImage\n",
    " \n",
    "\n",
    "  trainingPartition = pcImage.addBands(classes_w_barren_change_mask.select('landclass')).stratifiedSample(numPoints=20000,\n",
    "      classBand='landclass',\n",
    "      classValues=[0,1,2,3,4,5,6],\n",
    "      # classPoints=[1000,1000,1000,1000,1000,1000,1000], #[0,2000,2500,5000,5000,0,2000],\n",
    "      classPoints=[0,7540, 3530, 1400, 3750, 0, 2580],\n",
    "      scale=scale,\n",
    "      # tileScale=4,\n",
    "      seed=10,\n",
    "      region=aoi)\n",
    "  \n",
    "  # trainingPartition = pcImage.sampleRegions(\n",
    "  #     collection= combined_feature_collection,\n",
    "  #     properties=['landclass'],\n",
    "  #     scale=scale)\n",
    "  \n",
    "\n",
    "  print(\"training samples genereated\")\n",
    "  withRandom = trainingPartition.randomColumn();\n",
    "\n",
    "  split = 0.7  # Roughly 70% training, 30% testing.\n",
    "  trainingPartition = withRandom.filter(ee.Filter.lt('random', split))\n",
    "  testingPartition = withRandom.filter(ee.Filter.gte('random',split))\n",
    "\n",
    "  #Train from all sample data and test from clusters\n",
    "  # if image == \"after\":\n",
    "  #   pcImage = pcImage.updateMask(change_locations.select('labels'))\n",
    "\n",
    "  # testingPartition = pcImage.addBands(classes_w_barren_change_mask.select('landclass')).stratifiedSample(numPoints=10000,\n",
    "  #     classBand='landclass',\n",
    "  #     classValues=[0,1,2,3,4,5,6],\n",
    "  #     classPoints=stratifed_samples_sizes,\n",
    "  #     scale=scale,\n",
    "  #     tileScale=4,\n",
    "  #     seed=40,\n",
    "  #     region=aoi)\n",
    "\n",
    "  white_list_features = pcImage.bandNames().getInfo()\n",
    "  print(white_list_features)\n",
    "\n",
    "  def autoMLRF(image, training, testing):\n",
    "\n",
    "    white_list_features = image.bandNames().getInfo()\n",
    "    num_trees = [10,50,100,250,500] #,1000]\n",
    "    winner_score = 0\n",
    "    winner = None\n",
    "    winner_trees = 0\n",
    "    for t in num_trees:\n",
    "      classifier = ee.Classifier.smileRandomForest(numberOfTrees=t).train(features=training, classProperty='landclass',inputProperties= white_list_features)\n",
    "      validated = testing.classify(classifier)\n",
    "      testAccuracy = validated.errorMatrix('landclass', 'classification')\n",
    "      overallAccuracy = testAccuracy.accuracy().getInfo()\n",
    "      print(\"Trees: %s, OA: %s\" %(t, overallAccuracy))\n",
    "      if winner_score < overallAccuracy:\n",
    "        winner_score = overallAccuracy\n",
    "        winner = classifier\n",
    "        winner_trees = t\n",
    "  \n",
    "    print(\"Winner had Trees: %s, OA: %s\" %(winner_trees, winner_score))\n",
    "    # Get the most important features\n",
    "    white_list_feature_importance = createFeatureImportanceBarChart(winner, image_label).tolist()\n",
    "    print(white_list_feature_importance)\n",
    "    # Rerun winning classifier with important features\n",
    "    # winner = ee.Classifier.smileRandomForest(winner_trees).train(features=training, classProperty='landclass',inputProperties= white_list_features)\n",
    "    return winner\n",
    "\n",
    "  classifier = autoMLRF(pcImage, trainingPartition,testingPartition)\n",
    "    \n",
    "  #Classify the validation data.\n",
    "  validated = testingPartition.classify(classifier)\n",
    "\n",
    "  #post-processing\n",
    "  # water = classes_w_barren.select('landclass').eq(5).selfMask()\n",
    "  # roads = road_class.select('landclass').eq(0).selfMask().clipToCollection(aoi)\n",
    "  # notWater = classes_w_barren.select('landclass').neq(5).selfMask()\n",
    "  # validated = validated.where(water, water).where(roads, roads)\n",
    "\n",
    "  #Get a confusion matrix representing expected accuracy.\n",
    "  testAccuracy = validated.errorMatrix('landclass', 'classification')\n",
    "  print(' Resubstitution error matrix: ', testAccuracy.getInfo())\n",
    "  print(' Training overall accuracy: ', testAccuracy.accuracy().getInfo())\n",
    "  print(' Consumers accuracy: ', testAccuracy.consumersAccuracy().getInfo())\n",
    "  print(' Producers accuracy: ', testAccuracy.producersAccuracy().getInfo())\n",
    "  print(' Kappa: ', testAccuracy.kappa().getInfo())\n",
    "  # createConfusionMatixFigure(testAccuracy, label=image)\n",
    "\n",
    "\n",
    "  print(\"Classifier Created\")\n",
    "  #Classify the image with the same bands used for training.\n",
    "  #Mask out water since we are adding that in post processing\n",
    "  classified = pcImage.select(white_list_features).classify(classifier)\n",
    "  \n",
    "  #Apply median low-pass filter to smooth results\n",
    "  # post_classification = post_classification.focal_mode(1,'square', 'meters')\n",
    "  #Add water and roads from OSM to classification output\n",
    "  post_classification = (\n",
    "      classified\n",
    "        # .where(classes_w_barren.select('landclass').eq(5), water.multiply(5))\n",
    "        .where(water_class, 5)\n",
    "        .where(road_class.select('landclass').eq(0),0)\n",
    "        )\n",
    "  \n",
    "    \n",
    "  print(\"Image Classified\")\n",
    "  ps_collection_obcd_metrics[image] = {}\n",
    "  ps_collection_obcd_metrics[image][\"training\"] = trainingPartition\n",
    "  ps_collection_obcd_metrics[image][\"testing\"] = testingPartition\n",
    "  ps_collection_obcd_metrics[image][\"rawClassification\"] = classified\n",
    "  ps_collection_obcd_metrics[image][\"classifier\"] = classifier\n",
    "  ps_collection_obcd_metrics[image][\"accuracy\"] = testAccuracy\n",
    "\n",
    "  ps_collection_obcd_classified[image] = post_classification\n",
    "  return classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "nTx2Tp9Td6ui",
    "outputId": "0342f5a3-1190-426d-ce6e-0d934e18898a"
   },
   "outputs": [],
   "source": [
    "# for image in ps_collection_obcd:\n",
    "before_classified = classifyImage('before', aoi_bbox,scale=3)\n",
    "# exportEarthEngineImage(\n",
    "    # image=classifyImage('before', aoi_bbox),\n",
    "    # desc=\"before_image_classified\",\n",
    "    # imageName=\"before_image_classified\",\n",
    "    # region=aoi_bbox,\n",
    "    # saveLocation=\"CloudStorage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "J01HnAmnhxSv",
    "outputId": "388fafce-0912-442e-9a6c-6d312feeabbc"
   },
   "outputs": [],
   "source": [
    "createConfusionMatixFigure(ps_collection_obcd_metrics[\"before\"][\"accuracy\"], label=\"before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "HFPq7DBKeCre",
    "outputId": "86288810-0064-4146-965b-94db3e6e2f52"
   },
   "outputs": [],
   "source": [
    "after_classified = classifyImage('after', aoi_bbox, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "9w8u07tY4H40",
    "outputId": "c9d2d593-8815-4087-bc85-21f197a9cab0"
   },
   "outputs": [],
   "source": [
    "print(ps_collection_obcd_metrics)\n",
    "createConfusionMatixFigure(ps_collection_obcd_metrics[\"after\"][\"accuracy\"], label=\"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "_IO0sop-c0f0",
    "outputId": "c120fc61-aaa9-4bda-a4fa-a6ec6873cda7"
   },
   "outputs": [],
   "source": [
    "test = ps_collection_obcd_metrics[\"after\"][\"training\"].toList(10000).getInfo()\n",
    "type(test)\n",
    "list_of_properties = [f['properties'] for f in test]\n",
    "df = pd.DataFrame(list_of_properties)\n",
    "\n",
    "df[\"landcover\"] = df['landclass'].apply(str).map({\n",
    "    \"0\": 'road',\n",
    "    \"1\": 'building',\n",
    "    \"2\": 'barren',\n",
    "    \"3\": 'forest',\n",
    "    \"4\": 'grass',\n",
    "    \"5\": 'water',\n",
    "    \"6\": 'developed'\n",
    "})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "C3uW9WdYiVoh",
    "outputId": "77199352-0d61-4162-b695-dfd81e0dc153"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"landcover\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "QbN-5L2ZVBNf",
    "outputId": "8ee15cbf-971a-42ac-aa94-7b80c1254cc5"
   },
   "outputs": [],
   "source": [
    "\n",
    "pair_plot_palette = landcover_color_palette[1:5] + landcover_color_palette[6:7]\n",
    "\n",
    "sns.set_palette(sns.color_palette([\"#\" + c for c in pair_plot_palette]))\n",
    "sns.pairplot(df[['ndvi', 'ndwi', 'b1', 'b4', 'bsi','b4_median','b4_min', 'landcover']], hue='landcover')\n",
    "# ['pc3', 'pc7', 'pc10', 'pc13', 'pc11']\n",
    "\n",
    "# sns.pairplot(df[['pc12', 'pc4', 'pc3', 'pc11', 'pc6', 'landcover']], hue=\"landcover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "PjpWJVeA9VKe",
    "outputId": "ebf6efa0-b91f-4272-8fcb-e837b52711a5"
   },
   "outputs": [],
   "source": [
    "# water = classes.select('landclass').eq(5).selfMask()\n",
    "# barren = classes.select('landclass').eq(2).selfMask()\n",
    "  # classified = classified.cat(water)\n",
    "center_map = [cary_park.centroid().getInfo()['coordinates'][1],cary_park.centroid().getInfo()['coordinates'][0]]\n",
    "myMap = folium.Map(location=center_map, zoom_start=15, height=900)\n",
    "\n",
    "# myMap.add_ee_layer(water, {\"palette\": ['blue']}, 'water')\n",
    "\n",
    "\n",
    "for layer in ps_collection_obcd_classified:\n",
    "  myMap.add_ee_layer(ps_collection_obcd[layer].updateMask(aoi_mask), {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}, \"PS %s\" % layer)\n",
    "\n",
    "# for from_image_key in ps_collection_obcd_classified:\n",
    "myMap.add_ee_layer(ps_collection_obcd_classified[\"before\"].updateMask(aoi_mask), {\"min\": 0, \"max\": 6, \"palette\": landcover_color_palette, \"opacity\": 0.6}, \"%s\" % \"before\")\n",
    "myMap.add_ee_layer(ps_collection_obcd_classified[\"after\"].updateMask(aoi_mask), {\"min\": 0, \"max\": 6, \"palette\": landcover_color_palette, \"opacity\": 0.6}, \"%s\" % \"after\")\n",
    "\n",
    "\n",
    "\n",
    "# nlcd = ee.Image('USGS/NLCD/NLCD2016').clip(aoi)\n",
    "# myMap.add_ee_layer(nlcd.select('landcover'), {}, 'NLCD')\n",
    "# myMap.add_ee_layer(change_locations.randomVisualizer(), {}, \"Binary Change Mask\")\n",
    "\n",
    "# myMap.add_ee_layer(barren, {\"palette\": ['olive']}, 'barren')\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rtdtZtqPa4q"
   },
   "source": [
    "Export Classified Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFQvN9HbPZhO",
    "outputId": "05e5d808-2ea5-4fac-a13e-51ef2395e289"
   },
   "outputs": [],
   "source": [
    "# exportToDrive(ps_collection_obcd['before'],\"classified_before_30m\", resolution=30)\n",
    "# exportToDrive(ps_collection_obcd['after'],\"classified_after_30m\", resolution=30)\n",
    "print(f\"Before Classified: {ps_collection_obcd_classified['before'].bandNames().getInfo()}\")\n",
    "print(f\"After Classified: {ps_collection_obcd_classified['after'].bandNames().getInfo()}\")\n",
    "\n",
    "ee.batch.Export.image.toDrive(\n",
    "    image=ps_collection_obcd_classified['before'],\n",
    "    folder=figures_save_location,\n",
    "    description='classified_before_3m',\n",
    "    fileNamePrefix='classified_before_3m',\n",
    "    scale=3,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    region=aoi_bbox.geometry(),\n",
    "    formatOptions= {\"cloudOptimized\": True}).start()\n",
    "\n",
    "\n",
    "ee.batch.Export.image.toDrive(\n",
    "    image=ps_collection_obcd_classified['after'],\n",
    "    folder=figures_save_location,\n",
    "    description='classified_after_3m',\n",
    "    fileNamePrefix='classified_after_3m',\n",
    "    scale=3,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    region=aoi_bbox.geometry(),\n",
    "    formatOptions= {\"cloudOptimized\": True}).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX5_2Nodlyj_"
   },
   "source": [
    "## Generate Thematic Change Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA-ruZkbT4eQ"
   },
   "outputs": [],
   "source": [
    "ps_thematic_change_collection_obcd = {}\n",
    "for from_image_key in ps_collection_obcd_classified:\n",
    "  from_image = ps_collection_obcd_classified[from_image_key]\n",
    "  for to_image_key in ps_collection_obcd_classified:\n",
    "    if from_image_key != to_image_key:\n",
    "      to_image = ps_collection_obcd_classified[to_image_key]\n",
    "      thematic_change_key = \"from_%s_to_%s\" % (from_image_key, to_image_key)\n",
    "      thematic_change_image = generateThematicChangeImage(from_image, to_image, thematic_change_expression)\n",
    "      ps_thematic_change_collection_obcd[thematic_change_key] = thematic_change_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaVFoUyoUAP3",
    "outputId": "61279131-b06c-4be9-eaff-8ee0ffb299f4"
   },
   "outputs": [],
   "source": [
    "expression = \"\"\n",
    "for index, row in df_change_classes.iterrows():\n",
    "  expression = expression + \"(b('constant') == {}) ? {} :\".format(row['ClassID'],row[\"priority\"])\n",
    "\n",
    "expression = expression + \" 0\"\n",
    "\n",
    "print(expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEgL0XsIbcAw"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09YKYfPuXvaq",
    "outputId": "b6b27990-052b-4330-a558-fdd82e0091e2"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(change_locations.bandNames().getInfo())\n",
    "\n",
    "def getImageTotalArea(image):\n",
    "  print(\"AreaImage Start\")\n",
    "  areaImage = image.multiply(0).rename('area')\n",
    "  print(\"AreaImage End\")\n",
    "  totalArea = ee.Number(areaImage.add(1).reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= aoi,\n",
    "        scale= 30,\n",
    "        maxPixels= 1e12).get('area'))\n",
    "  return totalArea.divide(1e6).getInfo()\n",
    "\n",
    "print(\"totalArea: {} km2\".format(getImageTotalArea(ps_median.select('b3'))))\n",
    "print(\"Total Change Area: {} km2\".format(getImageTotalArea(change_locations.select('b3'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oyO2HmJVOUX",
    "outputId": "eb18d557-7b71-4109-d8d8-2739950d153c"
   },
   "outputs": [],
   "source": [
    "priority_change = (ps_thematic_change_collection_obcd['from_before_to_after']\n",
    "                   .expression(expression)\n",
    "                   .select(['constant'],['priority'])) \n",
    "                  #.clip(aoi)\n",
    "                  #.updateMask(change_locations.select('labels'))\n",
    "print(\"priority_change\")\n",
    "print(priority_change.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJuzh9QZU1du"
   },
   "outputs": [],
   "source": [
    "exportToDrive(priority_change,\"priority_change_30m\", resolution=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FF791rkgLNdd",
    "outputId": "e447e9e7-921f-4361-db30-0dbaedc6c5f8"
   },
   "outputs": [],
   "source": [
    "def printMinMax(image, imageName):\n",
    "  print(\"{0}:{1}\".format(imageName, image.reduceRegion(reducer= ee.Reducer.minMax(), geometry=aoi, scale=30,maxPixels= 1e16).getInfo()))\n",
    "\n",
    "priority_change_objectId = priority_change.addBands(change_locations.select(\"labels\"))\n",
    "objectSize = priority_change_objectId.select('labels').connectedPixelCount(128,False)\n",
    "print(\"objectSize: {}\".format(objectSize.bandNames().getInfo()))\n",
    "# printMinMax(objectSize,\"objectSize\")\n",
    "# Get a pixel area image.\n",
    "\n",
    "# Make sure pixels are set to correct scale 3m = 9m2\n",
    "pixelArea = priority_change_objectId.select('labels').multiply(0).add(9).rename('area')\n",
    "\n",
    "# pixelArea = ee.Image.pixelArea()\n",
    "printMinMax(pixelArea,\"pixelArea\")\n",
    "\n",
    "# Multiply pixel area by the number of pixels in an object to calculate\n",
    "# the object area. The result is an image where each pixel\n",
    "# of an object relates the area of the object in m^2.\n",
    "objectArea = objectSize.multiply(pixelArea).select(['labels'], ['area'])\n",
    "print(\"objectArea: {}\".format(objectArea.bandNames().getInfo()))\n",
    "printMinMax(objectArea,\"objectArea\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"priority_change_objectId: {}\".format(priority_change_objectId.bandNames().getInfo()))\n",
    "\n",
    "\n",
    "#Get the mean of the change areas priority and multiple it by the objects area\n",
    "objectPriority = priority_change_objectId.reduceConnectedComponents(reducer=ee.Reducer.mean(),labelBand= 'labels')\n",
    "print(\"objectPriority: {}\".format(objectPriority.bandNames().getInfo()))\n",
    "# printMinMax(objectPriority,\"objectPriority\")\n",
    "\n",
    "\n",
    "reducer = ee.Reducer.mean().splitWeights()\n",
    "objectPriorityWeighted = priority_change_objectId.addBands(objectArea.select(['area'])).reduceConnectedComponents(reducer=reducer,labelBand= 'labels')\n",
    "print(\"objectPriorityWeighted: {}\".format(objectPriorityWeighted.bandNames().getInfo()))\n",
    "# printMinMax(objectPriority,\"objectPriority\")\n",
    "\n",
    "# objectPriorityWeighted = objectPriority.divide(objectSize)\n",
    "# print(\"objectPriorityWeighted: {}\".format(objectPriorityWeighted.bandNames().getInfo()))\n",
    "# printMinMax(objectPriorityWeighted,\"objectPriorityWeighted\")\n",
    "\n",
    "\n",
    "priorityQueue = objectPriority.addBands([priority_change_objectId.select('labels'),objectArea.select('area')]).reduceConnectedComponents(reducer=ee.Reducer.product(),labelBand= 'labels')\n",
    "print(\"priorityQueue: {}\".format(priorityQueue.bandNames().getInfo()))\n",
    "# printMinMax(priorityQueue,\"priorityQueue\")\n",
    "\n",
    "\n",
    "priorityQueueMutli = objectPriority.multiply(objectArea)\n",
    "print(\"priorityQueueMutli: {}\".format(priorityQueueMutli.bandNames().getInfo()))\n",
    "# printMinMax(priorityQueueMutli,\"priorityQueueMutli\")\n",
    "\n",
    "\n",
    "\n",
    "myMap = folium.Map(location=center_map, zoom_start=16, height=900)\n",
    "\n",
    "for layer in ps_collection_obcd:\n",
    "  myMap.add_ee_layer(ps_collection_obcd[layer], {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}, \"PS %s\" % layer)\n",
    "\n",
    "# Priority Map\n",
    "priority_change_viz = {\"min\": 0, \"max\": 7, 'palette': ['feebe2','fcc5c0','fa9fb5','f768a1','dd3497','ae017e','7a0177']}\n",
    "myMap.add_ee_layer(priority_change, priority_change_viz, \"Priority Change\")\n",
    "\n",
    "\n",
    "# Mean Object Priority \n",
    "priority_queue_viz = {'opacity': 1, 'palette': [\"ffffb2\",\"fecc5c\",\"fd8d3c\",\"f03b20\",\"FF0000\"]}\n",
    "myMap.add_ee_layer(objectPriority.select('priority'), priority_queue_viz, 'Object Priority')\n",
    "myMap.add_ee_layer(objectPriorityWeighted.select('mean'), priority_queue_viz, 'Object Priority Weighted')\n",
    "\n",
    "# Obejct Size eg number of pixels\n",
    "object_size_viz = {'min':52, 'max':128,'opacity': 1, 'palette': [\"ffffb2\",\"fecc5c\",\"fd8d3c\",\"f03b20\",\"FF0000\"]}\n",
    "myMap.add_ee_layer(objectSize, object_size_viz, 'Object Size')\n",
    "\n",
    "# Object Area\n",
    "object_area_viz = {'min':468, 'max':1152,'opacity': 1, 'palette': [\"ffffb2\",\"fecc5c\",\"fd8d3c\",\"f03b20\",\"FF0000\"]}\n",
    "myMap.add_ee_layer(objectArea, object_area_viz, 'Object Area')\n",
    "\n",
    "\n",
    "priority_queue_viz = {'opacity': 1, 'palette': [\"ffffb2\",\"fecc5c\",\"fd8d3c\",\"f03b20\",\"FF0000\"]}\n",
    "myMap.add_ee_layer(priorityQueue.select('priority'), priority_queue_viz, 'Priority Queue')\n",
    "myMap.add_ee_layer(priorityQueueMutli.select('priority'), priority_queue_viz, 'Priority Queue Multi')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzf3Pp_6OODi",
    "outputId": "68dc4243-b402-4254-d07b-fd49329c5431"
   },
   "outputs": [],
   "source": [
    "print(priority_change.bandNames().getInfo())\n",
    "print(priorityQueueMutli.bandNames().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hr7Uv1Ylpn4D",
    "outputId": "543caa20-7791-4797-a1e2-7b908816bd68"
   },
   "outputs": [],
   "source": [
    "printMinMax(priorityQueueMutli,\"priorityQueueMutli\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnlN8L2mv25v",
    "outputId": "829b1664-8532-43a8-dfb0-17ec2f7ae8bc"
   },
   "outputs": [],
   "source": [
    "print(priorityQueueMutli.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DG22yurDwI0-"
   },
   "outputs": [],
   "source": [
    "ee.batch.Export.image.toDrive(\n",
    "    image=priorityQueue,\n",
    "    folder=figures_save_location,\n",
    "    description='priority_queue_30m',\n",
    "    fileNamePrefix='priority_queue_30m',\n",
    "    # fileNamePrefix='gee_priority_queue_multi_30m',\n",
    "    scale=30,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    region=aoi.geometry(),\n",
    "    # region=cary_park,\n",
    "    formatOptions= {\"cloudOptimized\": True}).start()\n",
    "\n",
    "ee.batch.Export.image.toDrive(\n",
    "    image=priority_change,\n",
    "    folder=figures_save_location,\n",
    "    description='priority_change_30m',\n",
    "    fileNamePrefix='priority_change_30m',\n",
    "    # fileNamePrefix='gee_priority_queue_multi_30m',\n",
    "    scale=30,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    region=aoi.geometry(),\n",
    "    # region=cary_park,\n",
    "    formatOptions= {\"cloudOptimized\": True}).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BM97tGBizUYG"
   },
   "outputs": [],
   "source": [
    "priority_queue_viz = {\n",
    "    'palette': [\"ffffb2\",\"fecc5c\",\"fd8d3c\",\"f03b20\",\"FF0000\"]\n",
    "    }\n",
    "\n",
    "ee.batch.Export.image.toDrive(\n",
    "    # image=priority_change.select('priority'),\n",
    "    # image=priorityQueue,\n",
    "    # image=priorityQueue.addBands(change_locations.select(\"labels\")).toDouble(),\n",
    "    image=priorityQueueMutli, #.addBands(change_locations.select(\"labels\")).toDouble(),\n",
    "    folder=figures_save_location,\n",
    "    description='priorit30myQueueMutli30m',\n",
    "    fileNamePrefix='priorityQueueMutli30m',\n",
    "    # fileNamePrefix='gee_priority_queue_multi_30m',\n",
    "    scale=30,\n",
    "    fileFormat= 'GeoTIFF',\n",
    "    region=aoi.geometry(),\n",
    "    # region=cary_park,\n",
    "    formatOptions= {\"cloudOptimized\": True}).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "ZveeUUaOzxKe",
    "outputId": "c40481ad-986b-4804-a725-2498e1ff64aa"
   },
   "outputs": [],
   "source": [
    "priorityQueueMutli.getDownloadURL({\n",
    "    \"palette\":[\"ffffb2\",\"fecc5c\",\"fd8d3c\",\"f03b20\",\"FF0000\"], \n",
    "    \"bands\":[\"priority\"],\n",
    "    \"scale\": 30,\n",
    "    \"region\":aoi.geometry()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "ifvlDZGRVS3R",
    "outputId": "35f387f5-2158-4d74-e507-64eb1135f491"
   },
   "outputs": [],
   "source": [
    "# priority_change_connected_components = priority_change.connectedComponents(ee.Kernal.square(10, 'pixels', True))\n",
    "#Uniquely label the hotspot image objects.\n",
    "hotspots = priority_change.updateMask(priority_change.gt(5))\n",
    "\n",
    "objectId = hotspots.connectedComponents(connectedness = ee.Kernel.square(1),maxSize = 128)\n",
    "#Compute the number of pixels in each object defined by the \"labels\" band.\n",
    "objectSize = objectId.select('labels').connectedPixelCount(maxSize= 128, eightConnected= True)\n",
    "#Get a pixel area image.\n",
    "pixelArea = ee.Image.pixelArea()\n",
    "#Multiply pixel area by the number of pixels in an object to calculate\n",
    "#the object area. The result is an image where each pixel\n",
    "#of an object relates the area of the object in m^2.\n",
    "objectArea = objectSize.multiply(pixelArea)\n",
    "areaMask = objectArea.gte(400)\n",
    "# Make a suitable image for `reduceConnectedComponents()` by adding a label\n",
    "# band to the `kelvin` temperature image.\n",
    "hotspots = hotspots.addBands(objectId.select(['labels']))\n",
    "#Calculate the mean temperature per object defined by the previously added\n",
    "#\"labels\" band.\n",
    "patchTemp = hotspots.reduceConnectedComponents(reducer = ee.Reducer.mean(),labelBand = 'labels',maxSize = 128)\n",
    "# print(patchTemp.bandNames().getInfo())\n",
    "#weight x area \n",
    "patchTempWeighted = patchTemp.multiply(objectArea).updateMask(areaMask)\n",
    "\n",
    "filter_geom = centenial\n",
    "# Normalize values between [0, 1]\n",
    "reducedDict = patchTempWeighted.reduceRegion(ee.Reducer.minMax(), filter_geom, scale=3, bestEffort= True, tileScale=16, crs='EPSG:3857',maxPixels= 1e12)\n",
    "\n",
    "# stdDev = ee.Number(image.reduceRegion(\n",
    "#       reducer= ee.Reducer.stdDev(),\n",
    "#       geometry= region,\n",
    "#       scale= scale,\n",
    "#       maxPixels= 1e12).get(band));\n",
    "\n",
    "# print(reducedDict.getInfo())\n",
    "minValue = reducedDict.get(\"constant_min\").getInfo()\n",
    "maxValue = reducedDict.get(\"constant_max\").getInfo()\n",
    "print(minValue)\n",
    "print(maxValue)\n",
    "normalizedPriorityChange = patchTempWeighted.unitScale(minValue, maxValue)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCVJUbeDVZce"
   },
   "outputs": [],
   "source": [
    "# Get AOI centroid\n",
    "center_map = [filter_geom.centroid().getInfo()['coordinates'][1],filter_geom.centroid().getInfo()['coordinates'][0]]\n",
    "\n",
    "# Create a folium map object.\n",
    "myMap = folium.Map(location=center_map, zoom_start=16, height=900)\n",
    "\n",
    "for layer in ps_collection_obcd_classified:\n",
    "  myMap.add_ee_layer(ps_collection_obcd[layer], {\"bands\":[\"b3\", \"b2\", \"b1\"], \"min\": 366, \"max\": 2617,\"gamma\":2}, \"PS %s\" % layer)\n",
    "\n",
    "# for from_image_key in ps_collection_obcd_classified:\n",
    "#   myMap.add_ee_layer(ps_collection_obcd_classified[from_image_key], {\"min\": 0, \"max\": 5, \"palette\": landcover_color_palette, \"opacity\": 0.4}, \"%s\" % from_image_key)\n",
    "\n",
    "# thematic_change = ps_thematic_change_collection_obcd['from_before_to_after']\n",
    "\n",
    "\n",
    "                     \n",
    "mask = priority_change.updateMask(priority_change.neq(0))\n",
    "mask = mask.focal_median(3, 'square')\n",
    "myMap.add_ee_layer(mask.updateMask(mask.gt(3)), {\"palette\": ['green','yellow','orange','red', 'purple'], \"opacity\":0.5}, \"Priority Change\")\n",
    "high_priority_mask = priority_change.updateMask(priority_change.eq(7))\n",
    "myMap.add_ee_layer(high_priority_mask, {\"palette\": ['purple'], \"opacity\":0.7}, \"High Priority Change\")\n",
    "\n",
    "\n",
    "myMap.add_ee_layer(patchTempWeighted, {\"palette\": ['ffffd9','edf8b1','c7e9b4','7fcdbb','41b6c4','1d91c0','225ea8','253494','081d58'], \"opacity\":0.7}, 'patchTempWeighted')\n",
    "\n",
    "myMap.add_ee_layer(normalized_priority_change, {\"min\": 0, \"max\": 1, \"palette\": ['ffffd9','edf8b1','c7e9b4','7fcdbb','41b6c4','1d91c0','225ea8','253494','081d58'], \"opacity\":0.7}, 'normalizedpatchTempWeighted')\n",
    "# myMap.add_ee_layer(normalized_priority_change, {\"min\": 0, \"max\": 1, \"palette\": ['orange', 'purple'], \"opacity\":0.7}, 'patchTempWeighted Orange')\n",
    "\n",
    "myMap.add_ee_layer(binary_change_mask_red.updateMask(red_change_mask), {\"max\": 1, 'min': 0, \"palette\": ['orange', 'purple'], 'opacity': 0.75}, 'Red Binary')\n",
    "\n",
    "# normalized = normalizedPriorityChange.focal_median(500,'square','meters')\n",
    "# myMap.add_ee_layer(normalized, {\"min\": 0, \"max\": 1, \"palette\": ['ffffd9','edf8b1','c7e9b4','7fcdbb','41b6c4','1d91c0','225ea8','253494','081d58'], \"opacity\":0.7}, 'patchTempWeighted normalized image')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# folium.GeoJson(aoi.toGeoJSON(), name=\"Study Area\").add_to(myMap)\n",
    "# Add a layer control panel to the map.\n",
    "myMap.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(myMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtSntmU9OrZo"
   },
   "outputs": [],
   "source": [
    "class_vis_Params = {'min':0, 'max':1, 'dimensions': 1000, \"palette\": ['ffffd9','edf8b1','c7e9b4','7fcdbb','41b6c4','1d91c0','225ea8','253494','081d58']}\n",
    "Image(url=normalized.clip(aoi)\n",
    "  .getThumbUrl(class_vis_Params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4up6v6PyQcG7"
   },
   "source": [
    "## Export Data to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1q1paJNQa4J"
   },
   "outputs": [],
   "source": [
    "#Export High Priority Change\n",
    "exportEarthEngineImage(\n",
    "    image=normalizedPriorityChange.visualize(bands=\"constant\", min=0, max=1, palette=['yellow','orange', 'red', 'purple']),\n",
    "    desc=\"HighPriorityChangeMapCentenial\", \n",
    "    imageName=\"HighPriorityChangeCentenial\",\n",
    "    region=centenial, \n",
    "    saveLocation=\"CloudStorage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AQyR5O9Vj5G"
   },
   "outputs": [],
   "source": [
    "#Export AOI\n",
    "for layer in ps_collection_obcd:\n",
    "  exportEarthEngineImage(\n",
    "    image=ps_collection_obcd[layer],\n",
    "    desc=\"AOI %s\" % layer, \n",
    "    imageName=\"AOI_%s\" % layer,\n",
    "    region=aoi, \n",
    "    saveLocation=\"CloudStorage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfbdhwgZWMQ1"
   },
   "outputs": [],
   "source": [
    "#Export LULC Maps\n",
    "for from_image_key in ps_collection_obcd_classified:\n",
    "  exportEarthEngineImage(\n",
    "    image=ps_collection_obcd_classified[from_image_key],\n",
    "    desc=\"LULC %s\" % layer, \n",
    "    imageName=\"LULC_%s\" % layer,\n",
    "    region=aoi, \n",
    "    saveLocation=\"CloudStorage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmB-874_Wime"
   },
   "outputs": [],
   "source": [
    " exportEarthEngineImage(\n",
    "    image=thematic_change,\n",
    "    desc=\"Thematic Change Map Raw\", \n",
    "    imageName=\"Raw_Thematic_Change\",\n",
    "    region=aoi, \n",
    "    saveLocation=\"CloudStorage\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rapid-dsm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
